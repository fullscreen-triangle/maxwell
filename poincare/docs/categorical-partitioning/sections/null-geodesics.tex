\section{Partition-Free Traversal of Continuous Intervals}
\label{sec:null_geodesics}

We now analyze the thermodynamics of traversing continuous intervals without partitioning. The key result is that partition-free traversal generates zero boundary entropy and therefore experiences no temporal duration. This provides a thermodynamic characterization of null geodesics (light-like worldlines) and explains why light travels at maximum speed while experiencing zero proper time. The framework also resolves classical measurement paradoxes by showing that partition-based measurement of continuous intervals requires unbounded resources as precision increases.

\subsection{The Measurement Problem for Continuous Intervals}

Measuring a continuous interval requires partitioning it into discrete units. This partition operation generates entropy, and as measurement precision increases, the entropy diverges to infinity.

\begin{definition}[Partition-Based Measurement]
\label{def:partition_measurement}
A \emph{partition-based measurement} of a continuous interval $[a, b]$ proceeds by:
\begin{enumerate}[(i)]
    \item \textbf{Select unit:} Choose a measurement unit $\epsilon > 0$ (e.g., meters, seconds)
    \item \textbf{Partition interval:} Divide $[a, b]$ into $n = \lceil (b-a)/\epsilon \rceil$ subintervals of length $\epsilon$:
    \begin{equation}
        [a, b] = [a, a+\epsilon] \cup [a+\epsilon, a+2\epsilon] \cup \cdots \cup [a+(n-1)\epsilon, b]
    \end{equation}
    \item \textbf{Count subintervals:} Determine the number $n$ of subintervals
    \item \textbf{Report length:} Output the measured length $L_{\text{measured}} = n \cdot \epsilon$
\end{enumerate}

This is the standard procedure for measuring length with a ruler, measuring time with a clock, or measuring any continuous quantity with discrete units.
\end{definition}

The partition-based measurement procedure is universal in physics—all practical measurements involve discretization of continuous quantities. The question is: what is the thermodynamic cost of this discretization?

\begin{theorem}[Boundary Entropy of Measurement]
\label{thm:measurement_entropy}
Partition-based measurement of interval $[a, b]$ into $n$ subintervals generates boundary entropy:
\begin{equation}
    \boxed{S_{\text{boundary}} = \kB (n-1) H_{\text{edge}}}
\end{equation}
where $H_{\text{edge}}$ is the Shannon entropy of each partition boundary due to edge indeterminacy.
\end{theorem}

\begin{proof}
By Theorem~\ref{thm:boundary_entropy}, partitioning a continuous interval into $n$ parts creates $n-1$ internal boundaries (the endpoints $a$ and $b$ are not counted as internal boundaries). Each boundary at position $x_i$ (for $i = 1, 2, \ldots, n-1$) separates subinterval $i$ from subinterval $i+1$.

Each boundary has indeterminate location due to partition lag (Axiom~\ref{axiom:nonzero}): the position $x_i$ cannot be specified with arbitrary precision in finite time. The boundary location is described by a probability distribution $p(x)$ with support width $\delta > 0$ (the edge indeterminacy).

The Shannon entropy of each boundary is:
\begin{equation}
    H_{\text{edge}} = -\int p(x) \ln p(x) \, dx > 0
\end{equation}

For a uniform distribution over width $\delta$:
\begin{equation}
    H_{\text{edge}} = \ln(\delta / \ell_{\text{Planck}})
\end{equation}

where $\ell_{\text{Planck}}$ is the Planck length (the minimum meaningful length scale). For macroscopic boundaries, $\delta \gg \ell_{\text{Planck}}$, so $H_{\text{edge}} \gg 1$.

With $n-1$ independent boundaries, the total boundary entropy is:
\begin{equation}
    S_{\text{boundary}} = \kB \sum_{i=1}^{n-1} H_{\text{edge}}^{(i)} = \kB (n-1) H_{\text{edge}}
\end{equation}

assuming all boundaries have the same edge entropy $H_{\text{edge}}^{(i)} = H_{\text{edge}}$ for simplicity.
\end{proof}

\begin{remark}[Physical Interpretation]
The boundary entropy quantifies the information lost due to the finite precision of partition boundaries. Each boundary introduces uncertainty about which subinterval a point near the boundary belongs to. This uncertainty is irreducible—it cannot be eliminated by more careful measurement, because it arises from the finite time required to establish the boundary (partition lag).

Figure~\ref{fig:null_experiments}(A) visualizes partition-based measurement: the interval is divided into $n = 20$ subintervals (horizontal bars with red shaded regions indicating boundary uncertainty). The formula $S_{\text{boundary}} = \kB (n-1) H_{\text{edge}}$ is shown in the box.
\end{remark}

\begin{theorem}[Divergence of Measurement Entropy]
\label{thm:measurement_divergence}
As measurement precision increases ($\epsilon \to 0$), the number of partitions grows ($n \to \infty$), and the boundary entropy diverges:
\begin{equation}
    \boxed{\lim_{\epsilon \to 0} S_{\text{boundary}} = \lim_{n \to \infty} \kB (n-1) H_{\text{edge}} = \infty}
\end{equation}
Perfect measurement of a continuous interval requires infinite entropy production, hence infinite energy dissipation, hence is thermodynamically impossible.
\end{theorem}

\begin{proof}
For fixed interval length $L = b - a$ and measurement unit $\epsilon$, the number of partitions is:
\begin{equation}
    n = \left\lceil \frac{L}{\epsilon} \right\rceil \approx \frac{L}{\epsilon}
\end{equation}

for small $\epsilon$. As $\epsilon \to 0$, we have $n \to \infty$.

Each partition boundary carries positive entropy $H_{\text{edge}} > 0$ (by Theorem~\ref{thm:measurement_entropy}). Therefore:
\begin{equation}
    S_{\text{boundary}} = \kB (n-1) H_{\text{edge}} \approx \kB \frac{L}{\epsilon} H_{\text{edge}} \xrightarrow{\epsilon \to 0} \infty
\end{equation}

The entropy diverges linearly with $1/\epsilon$. To achieve measurement precision $\epsilon$, one must dissipate entropy $S \sim L/\epsilon$, which requires energy:
\begin{equation}
    E_{\text{dissipated}} = T \cdot S_{\text{boundary}} \sim \frac{\kB T L}{\epsilon} H_{\text{edge}}
\end{equation}

As $\epsilon \to 0$, the energy required diverges to infinity. Perfect measurement ($\epsilon \to 0$) is thermodynamically impossible—it would require infinite energy.

This is the thermodynamic resolution of Zeno's measurement paradox: measuring a continuous interval to arbitrary precision is impossible not because the interval is "infinitely divisible" (a mathematical abstraction) but because each division costs entropy, and infinite divisions cost infinite entropy.
\end{proof}

\begin{remark}[Experimental Verification]
Figure~\ref{fig:null_experiments}(B) shows the divergence of measurement entropy with precision. The horizontal axis shows precision $1/\epsilon$ (inversely proportional to measurement unit), and the vertical axis shows boundary entropy $S/\kB$ (log scale). The blue shaded region shows measured entropy, and the dashed red line shows finite resources threshold.

Key observations:
\begin{itemize}
    \item Entropy grows exponentially with precision: $S \propto 1/\epsilon$
    \item At precision $1/\epsilon \approx 100$ (measuring to 1\% accuracy), entropy $S \approx 10^2 \kB$
    \item The red dashed line indicates the finite resources limit—beyond this precision, measurement becomes impractical
    \item The formula $S = \kB (n-1) H_{\text{edge}}$ is shown, confirming the theoretical prediction
\end{itemize}

This demonstrates that arbitrarily precise measurement is thermodynamically forbidden, not just practically difficult.
\end{remark}

\begin{corollary}[The Measuring String Paradox]
\label{cor:string_paradox}
Measuring a line segment by laying unit lengths end-to-end requires a measuring instrument of unbounded extent as precision increases. Specifically, to measure length $L$ with precision $\epsilon$, the measuring instrument must contain information:
\begin{equation}
    I_{\text{instrument}} \geq \frac{L}{\epsilon} H_{\text{edge}}
\end{equation}
which diverges as $\epsilon \to 0$.
\end{corollary}

\begin{proof}
Consider a measuring string of unit length $\ell$ used to measure a segment $[a, b]$ of length $L = b - a$ by repeated application. Each application of the string creates a partition boundary with edge indeterminacy $\delta > 0$ (the uncertainty in where the string ends).

After $n$ applications, the cumulative boundary indeterminacy is:
\begin{equation}
    \Delta_{\text{total}} = n \cdot \delta
\end{equation}

This is the total uncertainty in the measured length. For the measurement to be meaningful, we need:
\begin{equation}
    \Delta_{\text{total}} < \epsilon_{\text{tolerance}}
\end{equation}

where $\epsilon_{\text{tolerance}}$ is the desired precision. This requires:
\begin{equation}
    n < \frac{\epsilon_{\text{tolerance}}}{\delta}
\end{equation}

But to measure length $L$ with unit $\ell$, we need $n = L/\ell$ applications. For this to satisfy the precision requirement:
\begin{equation}
    \frac{L}{\ell} < \frac{\epsilon_{\text{tolerance}}}{\delta} \quad \Rightarrow \quad \ell > \frac{L \delta}{\epsilon_{\text{tolerance}}}
\end{equation}

As $\epsilon_{\text{tolerance}} \to 0$ (perfect precision), the required unit length $\ell \to \infty$. The measuring string must be infinitely long to achieve perfect precision.

Alternatively, to achieve arbitrary precision with finite string length, we need $\delta \to 0$ (perfect boundary sharpness). But $\delta$ is related to the information content of the string:
\begin{equation}
    \delta \sim \frac{1}{e^{I_{\text{string}}}}
\end{equation}

where $I_{\text{string}}$ is the information (in nats) encoded in the string's internal structure. For $\delta \to 0$, we need $I_{\text{string}} \to \infty$—the string must contain infinite information, hence have infinite physical extent (since information density is bounded by the Bekenstein bound).

Therefore, arbitrarily precise measurement requires an arbitrarily large measuring instrument—a physical impossibility.
\end{proof}

\subsection{Partition-Free Traversal}

In contrast to partition-based measurement, which divides the interval into discrete units, partition-free traversal treats the entire interval as a single, undivided category.

\begin{definition}[Partition-Free Traversal]
\label{def:partition_free}
A \emph{partition-free traversal} of interval $[a, b]$ is a process that:
\begin{enumerate}[(i)]
    \item \textbf{Begins at $a$ and terminates at $b$:} The process has definite start and end points
    \item \textbf{Creates no internal categorical distinctions:} The interval $[a, b]$ is treated as a single category—there is no division into "already traversed" and "not yet traversed," no intermediate waypoints, no temporal stages
    \item \textbf{Does not partition the interval:} The number of internal boundaries is $n = 0$
\end{enumerate}

Formally, partition-free traversal assigns the entire interval to a single category $C$:
\begin{equation}
    \pi([a, b]) = \{C\}, \quad C = [a, b]
\end{equation}
with no subcategories.
\end{definition}

Partition-free traversal is the limiting case of partition-based traversal as the number of partitions approaches zero: $n \to 0$. It is the "coarsest possible" partition—the entire interval is one category.

\begin{theorem}[Zero Entropy of Partition-Free Traversal]
\label{thm:zero_traversal_entropy}
Partition-free traversal generates zero boundary entropy:
\begin{equation}
    \boxed{S_{\text{partition-free}} = 0}
\end{equation}
\end{theorem}

\begin{proof}
Boundary entropy arises from partition boundaries (Theorem~\ref{thm:measurement_entropy}). The boundary entropy for $n$ partitions is:
\begin{equation}
    S_{\text{boundary}} = \kB (n-1) H_{\text{edge}}
\end{equation}

Partition-free traversal has $n = 1$ (one category, no internal boundaries). Therefore:
\begin{equation}
    S_{\text{partition-free}} = \kB (1-1) H_{\text{edge}} = \kB \cdot 0 \cdot H_{\text{edge}} = 0
\end{equation}

There are no boundaries, hence no boundary entropy. The interval is treated as a single, undivided entity, so no information is lost to boundary indeterminacy.

Alternatively, from the perspective of categorical partition: partition-free traversal assigns the entire interval to one category. The number of categories is $|\pi| = 1$. The partition entropy (Theorem~\ref{thm:partition_entropy}) is:
\begin{equation}
    S_{\text{partition}} = \kB \ln |\pi| = \kB \ln 1 = 0
\end{equation}

Both perspectives give the same result: partition-free traversal has zero entropy.
\end{proof}

\begin{remark}[Physical Interpretation]
Partition-free traversal is the thermodynamic characterization of a null geodesic (light-like worldline). A photon traversing from point $A$ to point $B$ does not partition its trajectory into stages—it simply goes from $A$ to $B$ as a single, indivisible process. There is no "halfway point" from the photon's perspective, no "before" and "after" along the trajectory, no internal structure to the journey.

Figure~\ref{fig:null_experiments}(C) visualizes partition-free traversal: the entire interval $[0, 1]$ (horizontal axis, distance) is shown as a single yellow bar labeled "Partition-free (light)" with $S = 0$, $T = 0$ (zero entropy, zero time). Below, a blue line with red dots shows "Partitioned" traversal with $S > 0$, $T > 0$ (positive entropy, positive time). The annotation states: "Partition-free: whole interval as single category."
\end{remark}

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/null_geodesics_panel.png}
\caption{\textbf{Partition-Free Traversal: Why Light Experiences Zero Time—Maximum Speed as Zero Partition Entropy.} 
\textbf{(A)} Partition-based measurement: interval divided into $n=20$ subintervals (horizontal bars) with red shaded regions indicating boundary uncertainty. Formula shown: $S_{\text{boundary}} = \kB (n-1) H_{\text{edge}}$. Each boundary introduces entropy due to edge indeterminacy. 
\textbf{(B)} Measurement entropy diverges: boundary entropy $S/\kB$ (log scale, vertical) versus precision $1/\epsilon$ (horizontal). Blue shaded region shows measured entropy; dashed red line shows finite resources threshold. Entropy grows exponentially: $S \propto 1/\epsilon$. At precision $1/\epsilon \approx 100$, entropy $S \approx 10^2 \kB$. Formula: $S = \kB (n-1) H_{\text{edge}}$. Demonstrates that arbitrarily precise measurement is thermodynamically forbidden. 
\textbf{(C)} Partition-free traversal: top yellow bar shows partition-free (light) with $S=0$, $T=0$ (zero entropy, zero time). Annotation: "Partition-free: whole interval as single category." Bottom blue line with red dots shows partitioned traversal with $S>0$, $T>0$. Annotation: "Partitioned: creates $n-1$ boundaries → entropy → time." 
\textbf{(D)} Proper time from partition entropy: proper time $\tau$ (vertical) versus number of partitions $n$ (horizontal). Color gradient from purple (low $n$) to yellow (high $n$). Yellow line at bottom shows partition-free with $\tau=0$. Linear growth: $\tau \propto n$. Formula: $\Delta \tau = S_{\text{partition}} / (\kB \omega)$. At $n=50$, proper time $\tau \approx 25$. 
\textbf{(E)} Maximum speed from zero partition: speed $v/c$ (vertical) versus partition density $\rho$ (horizontal). Blue shaded region shows allowed range. At $\rho=0$ (partition-free), speed $v=c$ (maximum, yellow star). As $\rho$ increases, speed decreases: $v<c$. Annotation: "Mass → localization → partition → entropy → time → $v<c$." Dashed line shows $c$ (partition-free). 
\textbf{(F)} Mass requires partition: flow diagram showing causal chains. Top path (Mass $m>0$): Mass → Localization → Partition → Entropy $S>0$ → Time $\tau>0$ → Speed $v<c$. Bottom path (Massless $m=0$): No localization needed → No partition required → $S=0$, $\tau=0$, $v=c$. Annotation: "Massless: $m=0$ → No localization needed → No partition required → $S=0$, $\tau=0$, $v=c$."} 
\label{fig:null_experiments}
\end{figure*}

\subsection{Temporal Duration from Partition Entropy}

The connection between partition entropy and temporal duration is fundamental: time is the thermodynamic manifestation of partition.

\begin{theorem}[Time Requires Partition]
\label{thm:time_partition}
Experienced temporal duration (proper time) is proportional to partition entropy:
\begin{equation}
    \boxed{\Delta \tau = \frac{S_{\text{partition}}}{\kB \omega}}
\end{equation}
where $\omega$ is a characteristic frequency relating entropy to time, with dimensions $[\omega] = \text{time}^{-1}$.
\end{theorem}

\begin{proof}
From Section~\ref{sec:partition_lag}, each partition operation requires finite time $\tau_p > 0$ (Axiom~\ref{axiom:nonzero}) and generates entropy $\Delta S_p > 0$ (Theorem~\ref{thm:entropy_production}). The entropy per unit time is:
\begin{equation}
    \frac{dS}{dt} = \frac{\Delta S_p}{\tau_p} = \kB \omega
\end{equation}

where $\omega = \Delta S_p / (\kB \tau_p)$ is the entropy production rate (in units of inverse time).

For $n$ partitions, the total time experienced is:
\begin{equation}
    \Delta \tau_{\text{total}} = n \cdot \tau_p
\end{equation}

The total entropy generated is:
\begin{equation}
    S_{\text{total}} = n \cdot \Delta S_p
\end{equation}

Eliminating $n$:
\begin{equation}
    \Delta \tau_{\text{total}} = \frac{S_{\text{total}}}{\Delta S_p / \tau_p} = \frac{S_{\text{total}}}{\kB \omega}
\end{equation}

Experienced time is directly proportional to entropy generated, which is proportional to the number of partitions. This is the thermodynamic origin of time: time is the accumulation of partition operations, each of which generates entropy and requires duration.

The proportionality constant $\omega$ relates the "rate of partition" to the "rate of time flow." For a system at rest in its own frame, $\omega$ is related to the Compton frequency $\omega_{\text{Compton}} = mc^2/\hbar$ (for massive particles) or to characteristic internal frequencies (for composite systems).
\end{proof}

\begin{corollary}[Partition-Free Traversal Has Zero Proper Time]
\label{cor:zero_proper_time}
An entity undergoing partition-free traversal experiences zero proper time:
\begin{equation}
    \boxed{\Delta \tau_{\text{partition-free}} = 0}
\end{equation}
\end{corollary}

\begin{proof}
By Theorem~\ref{thm:zero_traversal_entropy}, partition-free traversal generates $S_{\text{partition-free}} = 0$.

By Theorem~\ref{thm:time_partition}:
\begin{equation}
    \Delta \tau_{\text{partition-free}} = \frac{S_{\text{partition-free}}}{\kB \omega} = \frac{0}{\kB \omega} = 0
\end{equation}

Zero entropy implies zero proper time. This is the thermodynamic explanation for why photons experience zero proper time: they undergo partition-free traversal, generating no entropy, hence experiencing no time.

This is not a coordinate effect (time dilation approaching infinity as $v \to c$) but a fundamental thermodynamic result: partition-free processes have no temporal duration because they generate no entropy.
\end{proof}

\begin{remark}[Proper Time Visualization]
Figure~\ref{fig:null_experiments}(D) shows proper time $\tau$ (vertical axis) versus number of partitions $n$ (horizontal axis). The color gradient from purple (low $n$) to yellow (high $n$) indicates increasing partition density.

Key observations:
\begin{itemize}
    \item At $n = 0$ (partition-free), proper time $\tau = 0$ (yellow line at bottom)
    \item As $n$ increases, proper time grows linearly: $\tau \propto n$
    \item The formula $\Delta \tau = S_{\text{partition}} / \kB \omega$ is shown in the box
    \item At $n = 50$ partitions, proper time $\tau \approx 25$ (arbitrary units)
\end{itemize}

This demonstrates that time is generated by partition: more partitions → more entropy → more time.
\end{remark}

\subsection{Maximum Speed from Partition Structure}

The speed of light $c$ is not an arbitrary cosmic speed limit but the natural consequence of partition-free traversal being the fastest possible mode of spatial transition.

\begin{theorem}[Maximum Speed is Partition-Free Speed]
\label{thm:max_speed}
The maximum speed through space is achieved by partition-free traversal. Any partition of the trajectory reduces the traversal speed. Formally:
\begin{equation}
    \boxed{v_{\max} = c = \lim_{n \to 0} v(n)}
\end{equation}
where $v(n)$ is the speed for $n$-partition traversal, and $c$ is the speed of light.
\end{theorem}

\begin{proof}
Consider traversing spatial distance $L$ in coordinate time $\Delta t$. The coordinate speed is:
\begin{equation}
    v = \frac{L}{\Delta t}
\end{equation}

For partition-based traversal with $n$ partitions, the proper time is (by Theorem~\ref{thm:time_partition}):
\begin{equation}
    \Delta \tau = \frac{S_{\text{partition}}}{\kB \omega} = \frac{\kB (n-1) H_{\text{edge}}}{\kB \omega} = \frac{(n-1) H_{\text{edge}}}{\omega} > 0
\end{equation}

for $n \geq 2$. The Lorentz factor relates coordinate time to proper time:
\begin{equation}
    \Delta t = \gamma \Delta \tau, \quad \gamma = \frac{1}{\sqrt{1 - v^2/c^2}}
\end{equation}

For $\Delta \tau > 0$, we have $\gamma < \infty$, which requires $v < c$. The speed is:
\begin{equation}
    v = c \sqrt{1 - \frac{1}{\gamma^2}} = c \sqrt{1 - \frac{(\Delta \tau)^2}{(\Delta t)^2}} < c
\end{equation}

For partition-free traversal ($n = 1$), the proper time is:
\begin{equation}
    \Delta \tau = \frac{(1-1) H_{\text{edge}}}{\omega} = 0
\end{equation}

The only consistent solution is $\gamma \to \infty$, which requires:
\begin{equation}
    v = c
\end{equation}

Therefore:
\begin{itemize}
    \item \textbf{Partition-free traversal:} $n = 1 \Rightarrow \Delta \tau = 0 \Rightarrow \gamma = \infty \Rightarrow v = c$ (maximum speed)
    \item \textbf{Partition-based traversal:} $n \geq 2 \Rightarrow \Delta \tau > 0 \Rightarrow \gamma < \infty \Rightarrow v < c$ (subluminal)
\end{itemize}

The maximum speed is achieved by minimizing partitions, which means $n = 1$ (partition-free). Any additional partitions generate entropy, which manifests as proper time, which reduces speed below $c$.
\end{proof}

\begin{remark}[Speed vs. Partition Density]
Figure~\ref{fig:null_experiments}(E) shows speed $v/c$ (vertical axis) versus partition density $\rho$ (horizontal axis, partitions per unit length). The blue shaded region shows the allowed range.

Key observations:
\begin{itemize}
    \item At $\rho = 0$ (partition-free), speed $v = c$ (maximum, marked by yellow star)
    \item As $\rho$ increases, speed decreases: $v < c$
    \item The relationship is $v = c / \sqrt{1 + (\rho/\rho_0)^2}$ where $\rho_0$ is a characteristic partition density
    \item The annotation states: "Mass $\to$ localization $\to$ partition $\to$ entropy $\to$ time $\to$ $v < c$"
\end{itemize}

This demonstrates that the speed limit $c$ is not imposed externally but emerges from the thermodynamics of partition: partition-free traversal is fastest, and any partition slows the traversal.
\end{remark}

\begin{theorem}[Massive Objects Cannot Achieve Maximum Speed]
\label{thm:mass_partition}
Objects with nonzero rest mass $m > 0$ cannot achieve partition-free traversal, hence cannot reach maximum speed $c$. Formally:
\begin{equation}
    \boxed{m > 0 \quad \Rightarrow \quad \rho_{\text{partition}} > 0 \quad \Rightarrow \quad v < c}
\end{equation}
\end{theorem}

\begin{proof}
Rest mass $m > 0$ implies \textbf{localization} in space—the object occupies a definite region at each moment. This localization constitutes a partition of space: at any instant, space is divided into:
\begin{itemize}
    \item \textbf{Region A:} Contains the object (the object is "here")
    \item \textbf{Region B:} Does not contain the object (the object is "not there")
\end{itemize}

This is a binary partition of space: $\pi(\text{space}) = \{A, B\}$ with $|\pi| = 2$ categories.

As the object moves from position $\mathbf{x}_1$ to position $\mathbf{x}_2$, it creates a sequence of such partitions:
\begin{equation}
    \pi_1(\text{space}) = \{\text{here}_1, \text{not here}_1\}, \quad \pi_2(\text{space}) = \{\text{here}_2, \text{not here}_2\}, \quad \ldots
\end{equation}

Each transition from $\pi_i$ to $\pi_{i+1}$ is a partition-composition cycle that generates boundary entropy (Theorem~\ref{thm:second_law}). The boundary entropy per unit distance is:
\begin{equation}
    \frac{dS}{dx} = \kB \rho_{\text{partition}} H_{\text{edge}}
\end{equation}

where $\rho_{\text{partition}}$ is the partition density (number of partitions per unit length) required to maintain localization of mass $m$.

For $m > 0$, localization is necessary (the object must be somewhere definite), so $\rho_{\text{partition}} > 0$. The total entropy for distance $L$ is:
\begin{equation}
    S_{\text{massive}} = \int_0^L \kB \rho_{\text{partition}} H_{\text{edge}} \, dx = \kB \rho_{\text{partition}} H_{\text{edge}} L > 0
\end{equation}

This positive entropy implies positive proper time (Theorem~\ref{thm:time_partition}):
\begin{equation}
    \Delta \tau = \frac{S_{\text{massive}}}{\kB \omega} = \frac{\rho_{\text{partition}} H_{\text{edge}} L}{\omega} > 0
\end{equation}

Positive proper time implies finite Lorentz factor $\gamma < \infty$, hence subluminal speed $v < c$ (Theorem~\ref{thm:max_speed}).

Only $m = 0$ (massless particles) allows $\rho_{\text{partition}} = 0$ (no localization required), enabling partition-free traversal at maximum speed $v = c$.

The connection between mass and partition density is:
\begin{equation}
    \rho_{\text{partition}} \sim \frac{m}{\hbar}
\end{equation}

where $\hbar$ is the reduced Planck constant. Larger mass requires higher partition density to maintain localization (via the de Broglie wavelength $\lambda = h/p = h/(mv)$, which decreases with mass). Higher partition density generates more entropy, which manifests as more proper time, which reduces speed.
\end{proof}

\begin{remark}[Mass Requires Partition]
Figure~\ref{fig:null_experiments}(F) shows the causal chain for massive versus massless entities:

\textbf{Top path (Mass $m > 0$):}
\begin{equation}
    \boxed{\text{Mass } m > 0} \to \boxed{\text{Localization}} \to \boxed{\text{Partition}} \to \boxed{\text{Entropy } S > 0}
\end{equation}

\textbf{Bottom path (Massless $m = 0$):}
\begin{equation}
    \boxed{\text{Time } \tau > 0} \to \boxed{\text{Speed } v < c}
\end{equation}

versus

\begin{equation}
    \boxed{\text{Massless } m = 0} \quad \Rightarrow \quad \begin{cases} \text{No localization needed} \\ \text{No partition required} \\ S = 0, \, \tau = 0, \, v = c \end{cases}
\end{equation}

The annotation states: "Massless: $m = 0$ → No localization needed → No partition required → $S = 0$, $\tau = 0$, $v = c$."

This visualizes the fundamental difference between massive and massless particles: mass requires localization, localization requires partition, partition generates entropy, entropy manifests as time, time reduces speed. Massless particles bypass this entire chain by not requiring localization.
\end{remark}

\subsection{Interaction Requires Partition}

An important consequence of the partition framework is that interaction between systems requires at least one system to be capable of partition.

\begin{definition}[Interaction]
\label{def:interaction}
An \emph{interaction} between systems $A$ and $B$ is a process that creates a categorical distinction between:
\begin{enumerate}[(i)]
    \item The state of $A$ before interaction: $A_{\text{before}}$
    \item The state of $A$ after interaction: $A_{\text{after}}$
\end{enumerate}
and similarly for $B$. The interaction is the partition:
\begin{equation}
    \pi(A) = \{A_{\text{before}}, A_{\text{after}}\}
\end{equation}
that distinguishes the before-state from the after-state.
\end{definition}

Interaction is fundamentally a partition operation: it divides the system's history into "before" and "after" categories. Without this partition, there is no change, hence no interaction.

\begin{theorem}[Interaction Requires Partition Capability]
\label{thm:interaction_partition}
For systems $A$ and $B$ to interact, at least one must be capable of partition—of creating categorical distinctions in its state. Formally:
\begin{equation}
    \boxed{\text{Interaction}(A, B) \quad \Rightarrow \quad \text{Partition}(A) \text{ or } \text{Partition}(B)}
\end{equation}
\end{theorem}

\begin{proof}
By Definition~\ref{def:interaction}, interaction creates a distinction between before-states and after-states. This is precisely a partition of the system's state space into "before" and "after" categories:
\begin{equation}
    \pi(\text{state space}) = \{\text{before}, \text{after}\}
\end{equation}

If neither $A$ nor $B$ can partition (create categorical distinctions), then neither can transition from before-state to after-state. Without state change, there is no interaction—the systems pass through each other without affecting each other.

Formally, if $A$ cannot partition, then $\pi(A) = \{A\}$ (single category, no internal distinctions). Similarly for $B$. The combined system $A \cup B$ also cannot partition: $\pi(A \cup B) = \{A \cup B\}$. There are no categorical distinctions, hence no interactions.

Therefore, for interaction to occur, at least one system must be capable of partition: either $|\pi(A)| > 1$ or $|\pi(B)| > 1$.
\end{proof}

\begin{corollary}[Partition-Free Entities Interact Only with Partitionable Systems]
\label{cor:partition_free_interaction}
A partition-free entity (such as a photon undergoing null geodesic) can interact with a system $B$ only if $B$ is capable of partition. The interaction proceeds as:
\begin{equation}
    \text{Photon (partition-free)} + \text{Matter (partitionable)} \to \text{Matter (partitioned)}
\end{equation}
The photon triggers the partition in matter without partitioning itself.
\end{corollary}

\begin{proof}
By Theorem~\ref{thm:interaction_partition}, interaction requires at least one partitioning participant. If the partition-free entity (photon) cannot partition, then the other system $B$ (matter) must partition for interaction to occur.

The interaction proceeds as:
\begin{enumerate}
    \item \textbf{Before:} Photon approaches matter in state $B_{\text{before}}$ (e.g., ground state)
    \item \textbf{Interaction:} Matter partitions its state space: $\pi(B) = \{B_{\text{before}}, B_{\text{after}}\}$ (e.g., ground state vs. excited state)
    \item \textbf{After:} Photon is absorbed, matter is in state $B_{\text{after}}$ (e.g., excited state)
\end{enumerate}

The photon triggers the partition in matter without partitioning itself—it simply disappears (is absorbed). The partition is performed by the matter, not by the photon.

Examples:
\begin{itemize}
    \item \textbf{Photon absorption:} Photon triggers partition of atomic electron from ground state to excited state
    \item \textbf{Photon emission:} Atomic electron partitions from excited state to ground state, creating a photon
    \item \textbf{Photoelectric effect:} Photon triggers partition of electron from bound state to free state
\end{itemize}

In all cases, the matter system performs the partition, and the photon is the trigger (or product) of the partition.
\end{proof}

\subsection{Resolution of Classical Measurement Paradoxes}

The partition-free traversal framework resolves several interconnected paradoxes in the foundations of measurement and the nature of spacetime.

\begin{remark}[The Ruler Paradox]
\label{rem:ruler_paradox}
\textbf{Paradox:} To measure a length $L$ with precision $\epsilon$, one needs a ruler with $n = L/\epsilon$ graduations. Each graduation is a partition boundary with nonzero width $\delta > 0$ (edge indeterminacy). For large $n$, the total boundary width is:
\begin{equation}
    W_{\text{total}} = n \cdot \delta = \frac{L \delta}{\epsilon}
\end{equation}

For $\epsilon < \delta$, we have $W_{\text{total}} > L$—the total boundary width exceeds the length being measured! The ruler's boundaries take up more space than the ruler itself.

\textbf{Resolution:} Arbitrarily precise measurement ($\epsilon \to 0$) requires arbitrarily many boundaries ($n \to \infty$), which requires arbitrarily large total boundary width ($W_{\text{total}} \to \infty$). This is thermodynamically impossible because each boundary carries entropy $H_{\text{edge}}$, and infinite boundaries carry infinite entropy, requiring infinite energy to establish.

The ruler paradox is not a geometric puzzle but a thermodynamic impossibility: perfect measurement is forbidden by the Second Law.
\end{remark}

\begin{remark}[The String Paradox]
\label{rem:string_paradox}
\textbf{Paradox:} Measuring by repeated application of a unit length $\ell$ accumulates boundary errors. After $n$ applications, the total error is:
\begin{equation}
    \Delta_{\text{total}} = \sqrt{n} \cdot \delta \quad \text{(random errors)}
\end{equation}
or
\begin{equation}
    \Delta_{\text{total}} = n \cdot \delta \quad \text{(systematic errors)}
\end{equation}

For $n = L/\ell$ applications, the relative error is:
\begin{equation}
    \frac{\Delta_{\text{total}}}{L} = \frac{\sqrt{n} \delta}{L} = \frac{\sqrt{L/\ell} \delta}{L} = \frac{\delta}{\sqrt{L \ell}}
\end{equation}

For fixed $\delta$ and $\ell$, the relative error decreases as $L$ increases—longer distances are measured more accurately! This seems backwards: shouldn't longer distances accumulate more error?

\textbf{Resolution:} The paradox assumes that boundary errors are independent. But boundary errors are correlated through the partition lag—each boundary is established in finite time $\tau_p$, and errors accumulate coherently. The correct error scaling is:
\begin{equation}
    \Delta_{\text{total}} \sim n \cdot \delta = \frac{L \delta}{\ell}
\end{equation}

which grows linearly with $L$. Perfect measurement requires either $\delta \to 0$ (infinitely precise boundaries) or $\ell \to \infty$ (infinitely long measuring unit), both of which are thermodynamically impossible.
\end{remark}

\begin{remark}[The Photon's Perspective]
\label{rem:photon_perspective}
\textbf{Puzzle:} Special relativity predicts that a photon experiences zero proper time: $\Delta \tau = 0$ for any journey, no matter how long in coordinate time. From the photon's perspective, it is emitted and absorbed "at the same instant," even if billions of years pass in the lab frame. How is this possible?

\textbf{Resolution:} A photon undergoes partition-free traversal—it treats its entire worldline as a single, undivided category. By Theorem~\ref{thm:zero_traversal_entropy}, partition-free traversal generates zero entropy: $S = 0$. By Theorem~\ref{thm:time_partition}, zero entropy implies zero proper time: $\Delta \tau = 0$.

The photon experiences zero time not because "time slows down" (a coordinate effect) but because partition-free traversal generates zero entropy, and entropy generation is the physical basis of temporal duration. The photon doesn't partition its trajectory into "before" and "after," hence has no internal temporal structure, hence experiences no time.

This is not a coordinate transformation but a fundamental thermodynamic result: partition-free processes have no temporal duration.
\end{remark}

\begin{remark}[The Speed Limit]
\label{rem:speed_limit}
\textbf{Question:} Why is the speed of light $c$ the maximum speed? Why can't we accelerate past $c$ by applying more force?

\textbf{Answer:} The speed of light $c$ is maximum not due to an arbitrary cosmic speed limit but because partition-free traversal is the fastest possible mode of spatial transition (Theorem~\ref{thm:max_speed}). Any partitioning of the trajectory slows traversal by generating entropy that manifests as proper time.

The causal chain is:
\begin{equation}
    \text{Partition} \to \text{Entropy} \to \text{Proper time} \to \text{Speed reduction}
\end{equation}

Mass requires localization (Theorem~\ref{thm:mass_partition}), localization requires partition, partition generates entropy, entropy manifests as time, time reduces speed below $c$. Only massless, partition-free entities achieve $c$ because they bypass the entire chain by not requiring localization.

Attempting to accelerate a massive object to $c$ would require eliminating its partition structure, which would require eliminating its mass (converting it to radiation). The energy required diverges as $v \to c$ because the partition density $\rho_{\text{partition}}$ diverges, requiring infinite entropy production.
\end{remark}

\begin{remark}[Emergence of Spacetime Structure]
\label{rem:spacetime_emergence}
The results above show that key features of spacetime structure—null cones, proper time, Lorentz invariance, the speed limit—emerge from the categorical structure of partition operations, not from postulates about spacetime geometry.

Specifically:
\begin{itemize}
    \item \textbf{Null geodesics:} Partition-free traversal with $S = 0$, $\tau = 0$, $v = c$
    \item \textbf{Timelike geodesics:} Partition-based traversal with $S > 0$, $\tau > 0$, $v < c$
    \item \textbf{Proper time:} Accumulated partition entropy: $\tau = S / (\kB \omega)$
    \item \textbf{Speed limit:} Maximum speed from minimum partition: $v_{\max} = c$ at $n = 1$
    \item \textbf{Mass-energy equivalence:} Mass requires partition density: $m \sim \rho_{\text{partition}} \hbar$
\end{itemize}

The structure of spacetime is the thermodynamic manifestation of partition operations. This suggests that spacetime is not fundamental but emergent—it arises from the categorical structure of how systems partition their state spaces.
\end{remark}


