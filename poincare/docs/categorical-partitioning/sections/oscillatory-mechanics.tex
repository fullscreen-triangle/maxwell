\section{Entropy from Oscillatory Mechanics}
\label{sec:oscillatory}

We derive entropy from first principles of oscillatory dynamics, making no reference to categorical structure or partition operations. The derivation rests solely on the physics of bounded oscillating systems. This independent derivation establishes the oscillatory perspective as one of three equivalent foundations for thermodynamic entropy, which will be unified in Section~\ref{sec:unification}.

\subsection{Axioms of Oscillatory Systems}

Physical systems that exhibit thermodynamic behavior must satisfy certain fundamental constraints. We formalize these constraints as axioms that characterize the phase space structure and dynamical evolution of realistic physical systems.

\begin{axiom}[Boundedness]
\label{axiom:bounded}
Physical systems occupy bounded regions of phase space. For any system with generalised coordinates $\{q_i\}$ and momenta $\{p_i\}$, there exist finite bounds:
\begin{equation}
    |q_i| \leq Q_{\max}, \quad |p_i| \leq P_{\max}
\end{equation}
for all degrees of freedom $i = 1, 2, \ldots, M$.
\end{axiom}

The boundedness axiom reflects the physical reality that no system possesses infinite energy or extends to spatial infinity. Any isolated system has finite total energy $E_{\text{total}} < \infty$, which constrains both the kinetic energy (limiting momenta) and potential energy (limiting coordinate ranges). Systems violating this axiom—such as idealized free particles with unbounded momentum—do not exhibit thermodynamic behavior in the usual sense, as they lack the phase space compactness necessary for statistical equilibrium.

\begin{axiom}[Hamiltonian Dynamics]
\label{axiom:hamiltonian}
The time evolution preserves phase space volume (Liouville's theorem):
\begin{equation}
    \frac{d}{dt}\int_{\Omega} d^{2M}x = 0
\end{equation}
for any region $\Omega$ in phase space, where $M$ is the number of degrees of freedom and $d^{2M}x = dq_1 \cdots dq_M \, dp_1 \cdots dp_M$ is the phase space volume element.
\end{axiom}

Liouville's theorem is a fundamental consequence of Hamiltonian mechanics and expresses the incompressibility of phase space flow. The preservation of phase space volume under time evolution ensures that probability distributions evolve deterministically and that the microcanonical ensemble (uniform distribution over constant-energy surfaces) remains stationary. This axiom is essential for applying Poincaré's recurrence theorem, which requires measure-preserving dynamics.

\begin{axiom}[Nonlinear Coupling]
\label{axiom:nonlinear}
Physical systems exhibit nonlinear coupling between degrees of freedom. The Hamiltonian contains interaction terms:
\begin{equation}
    H = \sum_{i=1}^{M} H_i(q_i, p_i) + \sum_{i < j} V_{ij}(q_i, q_j)
\end{equation}
where $V_{ij} \neq 0$ for at least some pairs $(i, j)$, and at least one $V_{ij}$ is nonlinear in its arguments.
\end{axiom}

The nonlinearity axiom ensures that the system exhibits complex dynamics rather than trivial integrable motion. In the absence of nonlinear coupling, the system would decompose into independent harmonic oscillators with periodic motion and no energy exchange between modes. Nonlinearity is responsible for thermalization—the redistribution of energy among degrees of freedom that leads to thermal equilibrium. Real physical systems invariably contain nonlinear interactions: anharmonic terms in molecular potentials, electromagnetic interactions between charged particles, gravitational coupling in celestial mechanics, and so forth.

\begin{theorem}[Bounded Systems Oscillate]
\label{thm:bounded_oscillate}
Every dynamical system satisfying Axioms~\ref{axiom:bounded}--\ref{axiom:nonlinear} exhibits oscillatory behaviour in phase space. Specifically, the system does not settle into fixed points but instead repeatedly revisits regions of phase space, with dynamics decomposable into a spectrum of oscillatory modes.
\end{theorem}

\begin{proof}
Let $(X, d)$ be the bounded phase space with finite diameter $\text{diam}(X) = \sup_{x, y \in X} d(x, y) = R < \infty$, and let $\phi_t: X \to X$ be the Hamiltonian flow generated by the equations of motion. By Axiom~\ref{axiom:hamiltonian}, the flow preserves the natural phase space measure $\mu$ (Liouville measure), meaning that for any measurable set $A \subset X$, we have $\mu(\phi_t(A)) = \mu(A)$ for all times $t$.

We first establish that the system exhibits recurrent behavior. By Poincaré's recurrence theorem \citep{poincare1890}, for any measurable set $A \subset X$ with positive measure $\mu(A) > 0$, almost every point $x \in A$ (in the sense of measure theory) returns to $A$ infinitely often under the flow $\phi_t$. More precisely, for almost every $x \in A$, there exists a sequence of times $t_1 < t_2 < t_3 < \cdots$ with $t_n \to \infty$ such that $\phi_{t_n}(x) \in A$ for all $n$. We denote the characteristic recurrence time by $\tau_{\text{rec}}$, defined as the typical time scale for returns to a set of measure $\mu(A) \sim \mu(X)/2$ (half the phase space).

The recurrence theorem alone does not immediately imply oscillatory behavior in the usual sense—it merely guarantees that trajectories return to neighborhoods of their starting points. To establish that this recurrent motion is oscillatory (periodic or quasi-periodic), we must examine the structure of phase space under nonlinear Hamiltonian dynamics.

For systems with nonlinear coupling (Axiom~\ref{axiom:nonlinear}), the Kolmogorov-Arnold-Moser (KAM) theorem \citep{kolmogorov1954,arnold1963,moser1962} provides a detailed picture of phase space structure. The KAM theorem states that for Hamiltonian systems that are small perturbations of integrable systems, most of the phase space is foliated by invariant tori on which the motion is quasi-periodic (multi-frequency oscillation with incommensurate frequencies). Between these KAM tori lie chaotic regions where trajectories exhibit sensitive dependence on initial conditions but remain bounded within the finite phase space.

Both types of motion—quasi-periodic on KAM tori and chaotic in the gaps between tori—exhibit the recurrent behavior guaranteed by Poincaré's theorem. However, we must establish that this recurrent motion can be characterized as oscillatory. We define ``oscillatory behavior'' in a broad sense that encompasses:

\begin{enumerate}
    \item \textbf{Periodic orbits:} Trajectories satisfying $\phi_T(x) = x$ for some period $T > 0$, corresponding to exact oscillation with a single fundamental frequency $\omega = 2\pi/T$.
    
    \item \textbf{Quasi-periodic orbits:} Trajectories on invariant tori characterized by multiple incommensurate frequencies $\omega_1, \omega_2, \ldots, \omega_M$, such that the motion is a superposition of oscillations:
    \begin{equation}
        q_i(t) = \sum_{k=1}^{M} A_{ik} \cos(\omega_k t + \phi_{ik})
    \end{equation}
    where $A_{ik}$ are amplitudes and $\phi_{ik}$ are phases. Such trajectories never exactly repeat but densely fill the invariant torus.
    
    \item \textbf{Chaotic orbits with bounded recurrence:} Trajectories in chaotic regions that exhibit sensitive dependence on initial conditions but remain confined to the bounded phase space. While these trajectories are not periodic, they repeatedly visit all regions of the accessible phase space and can be characterized by a broad spectrum of frequencies.
\end{enumerate}

The key observation is that all three types of motion can be decomposed into oscillatory modes via Fourier analysis. For any trajectory $x(t) = (q_1(t), \ldots, q_M(t), p_1(t), \ldots, p_M(t))$ in the bounded phase space, we can compute the temporal Fourier transform over a time interval $[0, \tau_{\text{rec}}]$:
\begin{equation}
    \tilde{q}_i(\omega) = \frac{1}{\tau_{\text{rec}}} \int_0^{\tau_{\text{rec}}} q_i(t) e^{-i\omega t} \, dt
\end{equation}

For periodic and quasi-periodic motion, the Fourier transform consists of discrete peaks at the fundamental frequencies and their harmonics. For chaotic motion, the Fourier transform exhibits a continuous spectrum, but the power is still concentrated in a finite frequency range determined by the system's energy and the characteristic time scales of the dynamics.

In all cases, the motion can be represented as a superposition of oscillatory modes:
\begin{equation}
    q_i(t) = \sum_{k=1}^{M_{\text{eff}}} A_{ik}(t) \cos(\omega_k t + \phi_{ik}(t))
\end{equation}
where $M_{\text{eff}}$ is the effective number of independent oscillatory modes, and the amplitudes $A_{ik}(t)$ and phases $\phi_{ik}(t)$ may vary slowly for chaotic systems but remain bounded. The effective mode count $M_{\text{eff}}$ is determined by the number of independent frequencies required to capture the essential dynamics, which for a system with $M$ degrees of freedom is typically of order $M$.

We conclude that bounded Hamiltonian systems with nonlinear coupling do not settle into static equilibrium (fixed points) but instead exhibit oscillatory dynamics characterized by a spectrum of frequencies. This oscillatory behavior is the foundation for the entropy derivation that follows.
\end{proof}

\begin{remark}[Mode Counting and Effective Dimensionality]
The number of independent oscillatory modes $M$ requires careful definition, as it depends on the nature of the dynamics. For systems with weak nonlinearity that remain close to integrable, the mode count $M$ is simply the number of normal modes of the linearized system. These normal modes are the eigenvectors of the linearized equations of motion, and each corresponds to an independent oscillatory degree of freedom.

For strongly nonlinear or chaotic systems, the concept of normal modes breaks down, as the modes are no longer independent and energy is exchanged between them on short time scales. In this case, the effective mode count $M$ is determined by the dimension of the phase space:
\begin{equation}
    M = \frac{\text{dim}(X)}{2}
\end{equation}
where we divide by 2 because phase space has both position and momentum coordinates for each degree of freedom, but each pair $(q_i, p_i)$ corresponds to a single oscillatory mode.

Alternatively, for systems with complex dynamics, $M$ can be identified with the number of independent frequencies in the Fourier decomposition of the trajectory over the recurrence time $\tau_{\text{rec}}$. This operational definition counts the number of distinct frequency components required to reconstruct the motion to within a specified accuracy. For most physical systems, this frequency-based mode count agrees with the phase space dimensionality up to factors of order unity.

The key point is that $M$ is an intrinsic property of the system—it counts the number of independent ways in which the system can store and exchange energy through oscillatory motion. This quantity will play the role of ``dimensional depth'' in the entropy formula.
\end{remark}

\subsection{Oscillatory Mode Structure and Quantum Discretization}

Having established that bounded systems exhibit oscillatory behavior, we now formalize the structure of oscillatory modes and introduce the quantum discretization that allows us to count distinguishable states.

\begin{definition}[Oscillatory Mode]
\label{def:mode}
An \emph{oscillatory mode} is an independent degree of freedom characterised by a frequency $\omega_i$ and amplitude $A_i$. For a system with $M$ modes, the state is specified by the vector of mode amplitudes:
\begin{equation}
    \mathbf{A} = (A_1, A_2, \ldots, A_M)
\end{equation}
Each mode contributes independently to the total energy:
\begin{equation}
    E_{\text{total}} = \sum_{i=1}^{M} E_i(A_i)
\end{equation}
where $E_i(A_i)$ is the energy stored in mode $i$ as a function of its amplitude.
\end{definition}

For harmonic oscillators, the energy-amplitude relation is $E_i = \frac{1}{2} m \omega_i^2 A_i^2$, but the definition applies more generally to anharmonic systems where the relation may be nonlinear. The independence of modes means that the modes do not exchange energy on time scales short compared to the recurrence time $\tau_{\text{rec}}$, allowing us to treat each mode as a separate subsystem for the purpose of counting states.

To derive entropy, we must count the number of distinguishable states accessible to the system. In classical mechanics, phase space is continuous, and the number of states in any finite region is infinite. To obtain a finite count, we must introduce a discretization of phase space. This discretization arises naturally from quantum mechanics, which imposes a fundamental granularity on phase space through Planck's constant $\hbar$.

\begin{remark}[Classical to Quantum Transition]
The derivation thus far has been entirely classical, relying on Poincaré recurrence and Hamiltonian dynamics. However, to obtain a finite entropy, we must discretize the phase space into countable cells. There are two approaches to this discretization, both yielding the same result:

\textbf{Classical discretization:} We divide phase space into cells of volume $(\Delta q \Delta p)^M \sim h^M$ where $h$ is a fundamental action scale. The choice $h = 2\pi\hbar$ (Planck's constant) is motivated by the correspondence principle and ensures agreement with quantum mechanics in the appropriate limit. For a bounded phase space of total volume $V_{\text{phase}}$, the number of accessible cells is:
\begin{equation}
    W_{\text{classical}} = \frac{V_{\text{phase}}}{(2\pi\hbar)^M}
\end{equation}
The entropy is then $S = \kB \ln W_{\text{classical}}$. If each cell admits $n$ distinguishable configurations (e.g., different internal states), this becomes $S = \kB M \ln n$ after appropriate normalization.

\textbf{Quantum discretization:} We recognize that each classical oscillatory mode corresponds to a quantum harmonic oscillator with discrete energy levels. The quantum Hamiltonian for mode $i$ is:
\begin{equation}
    \hat{H}_i = \hbar \omega_i \left( \hat{a}_i^\dagger \hat{a}_i + \frac{1}{2} \right)
\end{equation}
where $\hat{a}_i$ and $\hat{a}_i^\dagger$ are the lowering and raising operators. The energy eigenvalues are:
\begin{equation}
    E_{n_i} = \hbar \omega_i \left( n_i + \frac{1}{2} \right)
\end{equation}
with $n_i \in \{0, 1, 2, \ldots\}$ the quantum number. Each value of $n_i$ corresponds to a distinct quantum state, providing a natural discretization of the classical amplitude continuum.

Both approaches yield the same entropy formula $S = \kB M \ln n$ when properly formulated. We adopt the quantum picture as it provides a physical justification for the discretization scale ($\hbar$) without introducing an arbitrary cutoff. The quantum discretization is not an approximation but a reflection of the fundamental structure of physical systems at microscopic scales.
\end{remark}

\begin{definition}[Quantum Oscillator States]
\label{def:quantum_states}
For quantum mechanical systems, each oscillatory mode $i$ admits discrete energy levels:
\begin{equation}
    E_{n_i} = \hbar \omega_i \left( n_i + \frac{1}{2} \right)
\end{equation}
where $n_i \in \{0, 1, 2, \ldots, n_{\max}\}$ is the quantum number and $n_{\max}$ is determined by the total energy available to the mode. The quantum state of mode $i$ is specified by the occupation number $n_i$, which counts the number of energy quanta $\hbar \omega_i$ stored in the mode.
\end{definition}

The maximum quantum number $n_{\max}$ is constrained by the total energy of the system. For a system in thermal equilibrium at temperature $T$, the average energy per mode is given by the equipartition theorem (in the classical limit) or by quantum statistical mechanics (in general). At temperature $T$, the average occupation number of a quantum harmonic oscillator is:
\begin{equation}
    \langle n_i \rangle = \frac{1}{e^{\hbar \omega_i / \kB T} - 1}
\end{equation}
This is the Bose-Einstein distribution for bosonic excitations (phonons, photons, etc.). In the high-temperature limit $\kB T \gg \hbar \omega_i$, this reduces to:
\begin{equation}
    \langle n_i \rangle \approx \frac{\kB T}{\hbar \omega_i}
\end{equation}
which corresponds to the classical equipartition result $\langle E_i \rangle = \kB T$ (since $E_i = \hbar \omega_i n_i$ for large $n_i$).

The maximum quantum number accessible at a temperature $T$ is therefore:
\begin{equation}
    n_{\max} \approx \frac{\kB T}{\hbar \omega}
\end{equation}
for modes with characteristic frequency $\omega$. This sets the scale for the number of distinguishable states per mode, which we denote by $n \equiv n_{\max} + 1$ (including the ground state $n = 0$).

\begin{figure*}[htbp]
\centering
\includegraphics[width=0.95\textwidth]{figures/oscillatory_reality_panel.png}
\caption{\textbf{Oscillatory Foundation of Physical Reality.} 
\textbf{(A)} Poincaré recurrence in bounded phase space: trajectories return infinitely often to initial neighborhoods, demonstrating that bounded Hamiltonian systems cannot settle into fixed points but must exhibit recurrent dynamics. The blue curve shows a typical trajectory in a two-dimensional phase space projection, with the initial point (red circle) and return point (green square) illustrating the recurrence property. 
\textbf{(B)} Quantum wavefunction oscillation: the spatial structure of a quantum state $\psi(x,t)$ (blue curve) and its probability density $|\psi(x,t)|^2$ (red shaded region) at a fixed time. The wavefunction is a superposition of modes with different frequencies $\omega_i$, leading to spatial oscillations. The probability density oscillates in both space and time, reflecting the wave nature of quantum mechanics. 
\textbf{(C)} Molecular vibrational modes at temperature $T > 0$: discrete energy levels $E_n = \hbar \omega (n + 1/2)$ for a quantum harmonic oscillator. Each mode can occupy states labeled by quantum number $n = 0, 1, 2, 3, \ldots$, with energy spacing $\hbar \omega$. The diagram shows a diatomic molecule oscillating between compressed and extended configurations, with the energy levels indicated on the right. At finite temperature, multiple levels are thermally accessible. 
\textbf{(D)} Vibrational configuration transitions: a system with $M = 3$ modes (three independent oscillators) and $n = 2$ states per mode (e.g., ground and first excited state). The five boxes show different configurations labeled by quantum number triples $(n_1, n_2, n_3)$. The total number of distinguishable configurations is $W = n^M = 2^3 = 8$, giving entropy $S = \kB M \ln n = \kB \cdot 3 \ln 2 \approx 2.88 \kB$. The red star indicates a transition between configurations. 
\textbf{(E)} Oscillation persists at all $T > 0$: vibrational energy (vertical axis) as a function of temperature (horizontal axis) for a quantum harmonic oscillator. The green curve shows the average energy $\langle E \rangle = \hbar \omega / 2 + \hbar \omega / (e^{\hbar \omega / \kB T} - 1)$, which approaches the zero-point energy $E_0 = \hbar \omega / 2$ (dashed line) as $T \to 0$ but never reaches zero. The cosmic microwave background temperature (2.7 K) is marked, demonstrating that even at the coldest naturally occurring temperature in the universe, oscillatory motion persists. This illustrates that oscillation is fundamental and never ceases. 
\textbf{(F)} Third law barrier prevents $T = 0$: polar plot showing the accessibility of different temperature states. The green region represents temperatures $T > 0$, which are physically accessible. The red central region represents the state $T = 0$ (absolute zero), which is unreachable due to the third law of thermodynamics. The barrier arises because the zero-point energy $E_0 = \hbar \omega / 2$ prevents complete cessation of oscillation—removing the last quantum of energy would require infinite time. The angular coordinate has no physical meaning; the plot simply visualizes the topological structure of the accessible state space (a disk with the center removed). This geometric representation emphasizes that $T = 0$ is not merely difficult to reach but is fundamentally excluded from the space of physical states.}
\label{fig:oscillatory_foundation}
\end{figure*}

\subsection{Derivation of Oscillatory Entropy}

We now derive the entropy of a system with $M$ oscillatory modes, each admitting $n$ distinguishable quantum states. The derivation proceeds by counting the total number of distinguishable configurations of the system and applying Boltzmann's fundamental relation between entropy and the number of microstates.

\begin{theorem}[Oscillatory Entropy]
\label{thm:osc_entropy}
For a system with $M$ oscillatory modes, each admitting $n$ distinguishable states, the entropy is:
\begin{equation}
    \boxed{\Sosc = \kB M \ln n}
\end{equation}
where $\kB$ is Boltzmann's constant, $M$ is the number of independent modes, and $n$ is the number of accessible states per mode.
\end{theorem}

\begin{proof}
The microstate of the system is completely specified by the vector of quantum numbers $\mathbf{n} = (n_1, n_2, \ldots, n_M)$, where each $n_i \in \{0, 1, 2, \ldots, n-1\}$ labels the quantum state of mode $i$. We assume that each mode can independently occupy any of $n$ states, which is valid when the modes are weakly coupled or when we consider the microcanonical ensemble at fixed total energy with energy broadly distributed among modes.

The total number of distinguishable configurations is obtained by counting the number of ways to assign quantum numbers to all $M$ modes. Since each mode has $n$ possible values and the modes are independent, the total count is:
\begin{equation}
    W_{\text{osc}} = \underbrace{n \times n \times \cdots \times n}_{M \text{ times}} = n^M
\end{equation}

This is the fundamental combinatorial result: the number of ways to make $M$ independent choices from $n$ options each is $n^M$.

By Boltzmann's relation $S = \kB \ln W$ \citep{boltzmann1877}, which connects the thermodynamic entropy $S$ to the number of accessible microstates $W$, we obtain:
\begin{equation}
    \Sosc = \kB \ln W_{\text{osc}} = \kB \ln(n^M)
\end{equation}

Using the logarithm property $\ln(n^M) = M \ln n$, we arrive at the final result:
\begin{equation}
    \Sosc = \kB M \ln n
\end{equation}

This formula has a clear physical interpretation: the entropy increases linearly with the number of modes $M$ (extensive property) and logarithmically with the number of states per mode $n$ (reflecting the information content per mode).
\end{proof}

\begin{remark}[Physical Interpretation]
The entropy formula $\Sosc = \kB M \ln n$ encodes several fundamental aspects of thermodynamic systems:

\begin{itemize}
    \item \textbf{Dimensional depth $M$:} The parameter $M$ counts the number of independent oscillatory degrees of freedom. This is the ``dimensionality'' of the system in the sense of how many independent ways it can store and exchange energy. The linear dependence $S \propto M$ reflects the extensivity of entropy—doubling the number of modes doubles the entropy, consistent with the additive nature of entropy for independent subsystems.
    
    \item \textbf{Branching factor $n$:} The parameter $n$ counts the number of distinguishable states per degree of freedom. This is the ``resolution'' or ``granularity'' of the state space—how finely we can distinguish different configurations of a single mode. The logarithmic dependence $S \propto \ln n$ reflects the information-theoretic nature of entropy: the information content of a choice among $n$ equally probable options is $\ln n$ nats (or $\log_2 n$ bits).
    
    \item \textbf{Boltzmann's constant $\kB$:} The factor $\kB = 1.380649 \times 10^{-23}$ J/K converts from dimensionless counting (the logarithm of the number of states) to thermodynamic units of energy per temperature. This conversion factor establishes the connection between the microscopic combinatorics of state counting and the macroscopic thermodynamic quantity of entropy measured in joules per kelvin.
    
    \item \textbf{Multiplicative structure:} The formula $S = \kB M \ln n$ can be rewritten as $S = \kB \ln(n^M)$, showing that the total number of states grows exponentially with the number of modes: $W = n^M$. This exponential growth is characteristic of systems with many degrees of freedom and is the origin of the second law of thermodynamics—the overwhelming majority of microstates correspond to macroscopic equilibrium.
\end{itemize}

The structure of this formula—linear in dimensional depth $M$, logarithmic in branching factor $n$—will reappear identically in the categorical and partition derivations (Sections~\ref{sec:categorical} and \ref{sec:partition}), establishing the fundamental equivalence of the three perspectives.
\end{remark}

\subsection{Temperature Dependence and Thermodynamic Limits}

The entropy formula $\Sosc = \kB M \ln n$ depends on temperature through the number of accessible states $n$, which is determined by the thermal energy $\kB T$ relative to the quantum energy scale $\hbar \omega$. We now examine this temperature dependence in detail and establish the behavior in various thermodynamic limits.

\begin{corollary}[Temperature Scaling]
\label{cor:temp_scaling}
For a system of $M$ harmonic oscillators at temperature $T$ with characteristic frequency $\omega$, the entropy exhibits the following temperature dependence:

\textbf{High temperature limit} ($\kB T \gg \hbar \omega$):
\begin{equation}
    \Sosc \approx \kB M \ln\left( \frac{\kB T}{\hbar \omega} \right) + \kB M
\end{equation}

\textbf{Low temperature limit} ($\kB T \ll \hbar \omega$):
\begin{equation}
    \Sosc \approx \kB M \frac{\hbar \omega}{\kB T} e^{-\hbar \omega / \kB T}
\end{equation}

\textbf{General case (all temperatures):}
\begin{equation}
    \Sosc = \kB M \left[ \frac{\hbar \omega / \kB T}{e^{\hbar \omega / \kB T} - 1} - \ln\left(1 - e^{-\hbar \omega / \kB T}\right) \right]
\end{equation}
\end{corollary}

\begin{proof}
We begin with the exact quantum statistical mechanical expression for the entropy of a single harmonic oscillator at temperature $T$. The partition function for a quantum harmonic oscillator is:
\begin{equation}
    Z = \sum_{n=0}^{\infty} e^{-\beta E_n} = \sum_{n=0}^{\infty} e^{-\beta \hbar \omega (n + 1/2)} = \frac{e^{-\beta \hbar \omega / 2}}{1 - e^{-\beta \hbar \omega}}
\end{equation}
where $\beta = 1/(\kB T)$. The free energy is:
\begin{equation}
    F = -\kB T \ln Z = \frac{\hbar \omega}{2} + \kB T \ln(1 - e^{-\hbar \omega / \kB T})
\end{equation}

The average energy is:
\begin{equation}
    \langle E \rangle = -\frac{\partial \ln Z}{\partial \beta} = \frac{\hbar \omega}{2} + \frac{\hbar \omega}{e^{\hbar \omega / \kB T} - 1}
\end{equation}

The entropy is obtained from $S = (\langle E \rangle - F)/T$:
\begin{equation}
    S = \kB \left[ \frac{\hbar \omega / \kB T}{e^{\hbar \omega / \kB T} - 1} - \ln\left(1 - e^{-\hbar \omega / \kB T}\right) \right]
\end{equation}

For a system of $M$ independent oscillators, the total entropy is $M$ times the single-oscillator entropy:
\begin{equation}
    \Sosc = \kB M \left[ \frac{\hbar \omega / \kB T}{e^{\hbar \omega / \kB T} - 1} - \ln\left(1 - e^{-\hbar \omega / \kB T}\right) \right]
\end{equation}

We now examine the limiting behavior:

\textbf{High temperature limit} ($\kB T \gg \hbar \omega$, or equivalently $\hbar \omega / \kB T \ll 1$):

Let $x = \hbar \omega / \kB T \ll 1$. We expand the exponentials:
\begin{align}
    e^x &\approx 1 + x + \frac{x^2}{2} + \cdots \\
    \frac{x}{e^x - 1} &\approx \frac{x}{x + x^2/2} = \frac{1}{1 + x/2} \approx 1 - \frac{x}{2} \\
    \ln(1 - e^{-x}) &\approx \ln(1 - 1 + x) = \ln x
\end{align}

Therefore:
\begin{equation}
    S \approx \kB M \left[ 1 - \frac{x}{2} - \ln x \right] = \kB M \left[ 1 + \ln\left(\frac{\kB T}{\hbar \omega}\right) \right]
\end{equation}

This can be written as:
\begin{equation}
    \Sosc \approx \kB M \ln\left( \frac{e \kB T}{\hbar \omega} \right)
\end{equation}

The factor $e$ comes from the zero-point energy contribution and can be absorbed into the definition of the reference state. The key result is that the entropy grows logarithmically with temperature in the classical limit.

\textbf{Low temperature limit} ($\kB T \ll \hbar \omega$, or equivalently $\hbar \omega / \kB T \gg 1$):

Let $x = \hbar \omega / \kB T \gg 1$. Then:
\begin{align}
    \frac{x}{e^x - 1} &\approx x e^{-x} \\
    \ln(1 - e^{-x}) &\approx \ln(e^{-x}) = -x
\end{align}

Therefore:
\begin{equation}
    S \approx \kB M \left[ x e^{-x} + x \right] = \kB M x (1 + e^{-x}) \approx \kB M x e^{-x}
\end{equation}

Substituting $x = \hbar \omega / \kB T$:
\begin{equation}
    \Sosc \approx \kB M \frac{\hbar \omega}{\kB T} e^{-\hbar \omega / \kB T}
\end{equation}

This shows that the entropy vanishes exponentially as $T \to 0$, consistent with the third law of thermodynamics. The exponential suppression reflects the fact that at low temperatures, only the ground state and a few low-lying excited states are thermally accessible.
\end{proof}

\begin{remark}[Connection to Theorem~\ref{thm:osc_entropy}]
The general temperature-dependent formula can be connected to the simpler form $S = \kB M \ln n$ by identifying the effective number of accessible states:
\begin{equation}
    n_{\text{eff}}(T) = \exp\left[ \frac{\hbar \omega / \kB T}{e^{\hbar \omega / \kB T} - 1} - \ln\left(1 - e^{-\hbar \omega / \kB T}\right) \right]
\end{equation}

In the high-temperature limit, this reduces to $n_{\text{eff}} \approx e \kB T / \hbar \omega$, confirming that the number of accessible states grows linearly with temperature. In the low-temperature limit, $n_{\text{eff}} \approx 1 + (\hbar \omega / \kB T) e^{-\hbar \omega / \kB T} \to 1$ as $T \to 0$, meaning that only the ground state is occupied.

The formula $S = \kB M \ln n$ with $n = n_{\text{eff}}(T)$ thus provides a unified description valid at all temperatures, with the temperature dependence encoded in the effective state count $n$.
\end{remark}

\begin{remark}[Third Law Compliance]
The low-temperature behavior $S \to 0$ as $T \to 0$ is consistent with the third law of thermodynamics, which states that the entropy of a perfect crystal approaches zero at absolute zero. However, absolute zero is unattainable in finite time, a consequence of the fact that removing the last quantum of energy from a harmonic oscillator requires infinite time (the cooling rate vanishes as $T \to 0$).

More fundamentally, the zero-point energy $E_0 = \hbar \omega / 2$ ensures that oscillation persists at all finite temperatures—the system never becomes completely static. This is illustrated in Figure~\ref{fig:oscillatory_foundation}(F), where the $T = 0$ state (center of the polar plot) is shown as unreachable (red region), while all $T > 0$ states are accessible (green region). The persistence of zero-point motion is a purely quantum mechanical effect with no classical analog, and it represents the fundamental limit to the cessation of oscillatory dynamics.
\end{remark}

\subsection{Independence from Categorical and Partition Concepts}

We emphasize that the derivation of the oscillatory entropy formula $\Sosc = \kB M \ln n$ has proceeded entirely within the framework of physical dynamics and statistical mechanics, with no reference to abstract categorical structures or partition operations. The derivation relies solely on the following physical principles:

\begin{enumerate}
    \item \textbf{Boundedness of phase space} (Axiom~\ref{axiom:bounded}): Physical systems have finite energy and occupy finite regions of phase space.
    
    \item \textbf{Hamiltonian dynamics} (Axiom~\ref{axiom:hamiltonian}): Time evolution preserves phase space volume, ensuring the applicability of Poincaré's recurrence theorem.
    
    \item \textbf{Nonlinear coupling} (Axiom~\ref{axiom:nonlinear}): Interactions between degrees of freedom lead to complex dynamics and energy redistribution, preventing the system from settling into trivial fixed points.
    
    \item \textbf{Quantum discretization of energy levels} (Definition~\ref{def:quantum_states}): The quantum mechanical structure of harmonic oscillators provides a natural discretization of the classical phase space continuum, allowing us to count distinguishable states.
    
    \item \textbf{Boltzmann's entropy relation} $S = \kB \ln W$: The fundamental connection between thermodynamic entropy and the number of accessible microstates, established by Boltzmann in the 19th century.
\end{enumerate}

No reference has been made to:
\begin{itemize}
    \item Categorical structures (objects, morphisms, functors)
    \item Partition operations (dividing wholes into parts)
    \item Information-theoretic concepts beyond the basic notion of counting distinguishable states
    \item Abstract algebraic or topological structures
\end{itemize}

The entropy $\Sosc = \kB M \ln n$ arises purely from the physics of bounded oscillating systems—the counting of quantum states in a system with $M$ independent modes, each admitting $n$ distinguishable configurations. This physical derivation establishes the oscillatory perspective as one of three independent foundations for thermodynamic entropy.

The subsequent sections will demonstrate that entirely different starting points—categorical enumeration (Section~\ref{sec:categorical}) and partition branching (Section~\ref{sec:partition})—yield the identical formula $S = \kB M \ln n$ with the same structural form (linear in $M$, logarithmic in $n$). This convergence from independent axioms is not coincidental but reveals a fundamental equivalence: oscillation, category, and partition are three perspectives on a single underlying structure. The proof of this equivalence is the subject of Section~\ref{sec:unification}.


