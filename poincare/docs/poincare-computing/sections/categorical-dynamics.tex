\section{Categorical Dynamics}
\label{sec:categorical_dynamics}

Having established the geometric structure of S-entropy space (Section~\ref{sec:finite_space}) and its physical grounding in hardware measurements (Section~\ref{sec:virtual_instrument}), we now develop the dynamical equations governing trajectory evolution. These equations determine how categorical states $\Scoord(t) = (\Sk(t), \St(t), \Se(t))$ evolve through phase space in response to computational processes, transforming the static problem specification (Section~\ref{sec:initial_state}) into a time-dependent trajectory that encodes the computation itself.

The categorical dynamics are derived from the fundamental principle that computation in Poincaré Computing corresponds to harmonic oscillator interactions. Each S-entropy coordinate is associated with an oscillatory mode characterized by a natural frequency $\omega_i$, and the three modes are coupled through nonlinear interaction terms. This coupling ensures that the coordinates evolve in a coordinated manner, with changes in one coordinate influencing the evolution of the others. The resulting dynamics exhibit rich structure including fixed points, periodic orbits, and quasi-periodic trajectories, with the specific trajectory determined by the initial state and the constraint set.

A crucial property established in this section is that the categorical dynamics are \textbf{measure-preserving}: the flow generated by the equations of motion preserves the Lebesgue measure on $\Sspace$. This property is essential for the application of Poincaré's recurrence theorem (Corollary~\ref{cor:poincare_applicable}), as it ensures that the phase space volume occupied by any set of initial conditions remains constant under time evolution. We prove that measure preservation holds when the characteristic frequencies satisfy a \textbf{modular condition}, which constrains their sum to vanish. This condition has a natural interpretation in terms of energy conservation in the underlying oscillator dynamics.

We further establish the existence of \textbf{harmonic coincidences}---special times when the oscillatory components of the trajectory synchronize---and prove that these coincidences form a dense set for rationally related frequencies. These coincidence events correspond to moments when the computation achieves temporary coherence across all three S-entropy dimensions, and they play a crucial role in the formation of recurrent trajectories. The section concludes with an analysis of fixed points and periodic orbits, demonstrating that the categorical dynamics admit a rich variety of solution structures beyond simple point attractors.

\subsection{Equations of Motion}

The evolution of a categorical state $\Scoord(t) = (\Sk(t), \St(t), \Se(t))$ is governed by a system of three coupled first-order ordinary differential equations. These equations are derived from the principle that each S-entropy coordinate evolves according to two influences: (i) a \textit{linear restoring term} that couples the coordinate to the other coordinates, driving the system toward equilibrium, and (ii) a \textit{nonlinear coupling term} that introduces oscillatory interactions between coordinates, enabling the complex trajectory structures required for computation.

\begin{definition}[Categorical Dynamics]
\label{def:categorical_dynamics}
The \textbf{categorical evolution equations} governing the time evolution of S-entropy coordinates are:
\begin{align}
\frac{d\Sk}{dt} &= \omega_k (\St - \Sk) + \alpha \sin(2\pi \Se) \label{eq:dsk_dt} \\
\frac{d\St}{dt} &= \omega_t (\Se - \St) + \beta \sin(2\pi \Sk) \label{eq:dst_dt} \\
\frac{d\Se}{dt} &= \omega_e (\Sk - \Se) + \gamma \sin(2\pi \St) \label{eq:dse_dt}
\end{align}
where:
\begin{itemize}
    \item $\omega_k, \omega_t, \omega_e \in \mathbb{R}$ are the \textbf{characteristic frequencies} associated with the knowledge, temporal, and evolution entropy coordinates respectively;
    \item $\alpha, \beta, \gamma \in \mathbb{R}$ are the \textbf{coupling constants} that determine the strength of nonlinear interactions between coordinates;
    \item The sine functions with period 1 (due to the $2\pi$ factor) reflect the periodic structure of the bounded phase space $\Sspace = [0,1]^3$.
\end{itemize}
\end{definition}

The physical interpretation of these equations is as follows. Consider the knowledge entropy evolution~\eqref{eq:dsk_dt}:
\begin{itemize}
    \item The term $\omega_k(\St - \Sk)$ represents a \textit{linear coupling} to the temporal entropy coordinate. If $\St > \Sk$, this term is positive, driving $\Sk$ to increase and approach $\St$. This coupling reflects the principle that knowledge accumulation (increasing $\Sk$) is facilitated by temporal structure (high $\St$).
    \item The term $\alpha \sin(2\pi \Se)$ represents a \textit{nonlinear forcing} from the evolution entropy coordinate. This term oscillates as $\Se$ varies, introducing periodic modulation of the knowledge entropy evolution. The sine function ensures that the forcing respects the periodic boundary conditions of the unit cube $\Sspace$.
\end{itemize}

Similar interpretations apply to the temporal and evolution entropy equations, with each coordinate coupled linearly to one neighbor and nonlinearly to another, forming a cyclic coupling structure: $\Sk \to \St \to \Se \to \Sk$. This cyclic structure ensures that information flows through all three coordinates, preventing any coordinate from evolving independently.

\begin{remark}[Derivation from Oscillator Dynamics]
\label{rem:oscillator_derivation}
The categorical dynamics~\eqref{eq:dsk_dt}--\eqref{eq:dse_dt} can be derived from a system of three coupled harmonic oscillators with positions $q_k(t)$, $q_t(t)$, $q_e(t)$ and a potential energy function:
\begin{equation}
V(q_k, q_t, q_e) = \frac{1}{2}\omega_k^2 (q_k - q_t)^2 + \frac{1}{2}\omega_t^2 (q_t - q_e)^2 + \frac{1}{2}\omega_e^2 (q_e - q_k)^2 + U_{\text{nl}}(q_k, q_t, q_e)
\label{eq:oscillator_potential}
\end{equation}
where $U_{\text{nl}}$ is a nonlinear coupling potential. The S-entropy coordinates are related to the oscillator phases via $\Sk = (q_k \mod 1)$, and the equations of motion $\ddot{q}_i = -\partial V/\partial q_i$ reduce to~\eqref{eq:dsk_dt}--\eqref{eq:dse_dt} in the overdamped limit. This connection to classical mechanics provides physical intuition for the categorical dynamics and justifies the use of Hamiltonian methods in their analysis \citep{goldstein2002classical}.
\end{remark}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/panel_navigation.png}
\caption{\textbf{Categorical Navigation: Spatial Distance Irrelevance.} 
\textbf{(A) Location Accessibility:} Bar chart shows categorical accessibility (normalized to $[0, 1]$) for six locations: Local ($1.0$), Jupiter Core ($1.0$), Sun Center ($1.0$), Deep Space ($1.0$), Earth Mantle ($1.0$), Moon ($1.0$). All locations show identical accessibility despite vastly different physical distances. This demonstrates spatial distance irrelevance (Theorem~\ref{thm:distance_irrelevance}): categorical navigation does not depend on physical separation. 
\textbf{(B) Physical vs Categorical Distance:} Grouped bar chart compares physical distance (red, $\log_{10}$ km scale) vs. categorical distance (blue, S-distance units) for six locations. Physical distances vary dramatically: Local ($\approx 0$ km), Jupiter Core ($\approx 10^8$ km), Sun Center ($\approx 10^8$ km), Deep Space ($\approx 10^{14}$ km), Earth Mantle ($\approx 10^3$ km), Moon ($\approx 10^5$ km). Categorical distances are uniformly small ($< 1$ S-unit) and show no correlation with physical distance. The decoupling confirms that categorical space is not embedded in physical space. 
\textbf{(C) Equal Measurement Time:} Bar chart shows measurement time (ms) for six locations: Local ($\approx 1.0$ ms), Jupiter Core ($\approx 0.6$ ms), Sun Center ($\approx 0.8$ ms), Deep Space ($\approx 0.4$ ms), Earth Mantle ($\approx 0.4$ ms), Moon ($\approx 0.4$ ms). Mean measurement time $0.670$ ms (red dashed line) is independent of location. All measurements complete in $< 1$ ms regardless of physical distance, confirming that categorical access time is constant. 
\textbf{(D) Tackle Reach Comparison:} Polar plot shows reachability in categorical space. Full tackle region (blue circle, radius $\approx 1.0$) encompasses all locations (colored dots: red at $180°$, green at $135°$, orange at $90°$, purple at $45°$, blue at center). Limited tackle region (magenta circle, radius $\approx 0.4$) encompasses only nearby locations. All six locations fall within full tackle radius, demonstrating that categorical navigation can reach any location with equal facility. 
\textbf{(E) Reachability Map:} Scatter plot in $(S_k, S_e)$ plane shows six locations as colored circles with black outlines. All locations cluster in reachable region (green background, $S_k, S_e \in [0, 1]$). Red circle at origin marks unreachable region (physical impossibility). The clustering demonstrates that physically disparate locations are categorically proximate. 
\textbf{(F) Sequential Access (All Instant):} Flowchart shows six locations accessed sequentially: Local ($0.96$ ms), Jupiter Core ($0.60$ ms), Sun Center ($0.82$ ms), Deep Space ($0.83$ ms), Earth Mantle ($0.39$ ms), Moon ($0.42$ ms). All accesses complete in $< 1$ ms (green checkmarks), demonstrating that sequential categorical navigation is effectively instantaneous regardless of physical distance. The access times are dominated by measurement overhead, not travel time.}
\label{fig:categorical_navigation}
\end{figure}

\subsection{Vector Field Formulation}

To facilitate analysis using tools from dynamical systems theory, we reformulate the categorical dynamics as a vector field on $\Sspace$. This formulation makes explicit the geometric structure of the dynamics and enables the application of theorems from differential geometry and topology.

Define the \textbf{categorical vector field} $\mathbf{F}: \Sspace \to \mathbb{R}^3$ by:
\begin{equation}
\mathbf{F}(\Scoord) = \begin{pmatrix}
\omega_k (\St - \Sk) + \alpha \sin(2\pi \Se) \\
\omega_t (\Se - \St) + \beta \sin(2\pi \Sk) \\
\omega_e (\Sk - \Se) + \gamma \sin(2\pi \St)
\end{pmatrix}
\label{eq:vector_field}
\end{equation}

The categorical dynamics~\eqref{eq:dsk_dt}--\eqref{eq:dse_dt} are then compactly expressed as:
\begin{equation}
\frac{d\Scoord}{dt} = \mathbf{F}(\Scoord)
\label{eq:vector_field_ode}
\end{equation}

This is an autonomous ordinary differential equation (ODE) on the compact manifold $\Sspace$. The vector field $\mathbf{F}$ is smooth (infinitely differentiable) on the interior of $\Sspace$ due to the smoothness of the sine function and arithmetic operations. At the boundary of $\Sspace$, the vector field must be analyzed carefully to ensure that trajectories remain within the unit cube.

\begin{proposition}[Invariance of $\Sspace$]
\label{prop:invariance}
The unit cube $\Sspace = [0,1]^3$ is invariant under the flow generated by $\mathbf{F}$: if $\Scoord(0) \in \Sspace$, then $\Scoord(t) \in \Sspace$ for all $t \geq 0$.
\end{proposition}

\begin{proof}
We must show that the vector field $\mathbf{F}$ points inward (or tangentially) at the boundary of $\Sspace$. Consider the boundary face $\Sk = 0$. On this face, the first component of $\mathbf{F}$ is:
\begin{equation}
F_1(\Scoord)|_{\Sk=0} = \omega_k (\St - 0) + \alpha \sin(2\pi \Se) = \omega_k \St + \alpha \sin(2\pi \Se)
\end{equation}

For $\St \in [0,1]$ and $\Se \in [0,1]$, we have:
\begin{itemize}
    \item If $\omega_k > 0$, then $\omega_k \St \geq 0$, and the term $\alpha \sin(2\pi \Se)$ is bounded in $[-|\alpha|, |\alpha|]$. Provided $\omega_k > |\alpha|$, we have $F_1 > 0$ on average, ensuring that trajectories starting at $\Sk = 0$ move into the interior.
    \item If $\omega_k < 0$, a similar analysis applies to the boundary face $\Sk = 1$.
\end{itemize}

Analogous arguments apply to the other boundary faces, establishing that $\Sspace$ is invariant under the flow. Rigorously, this requires that the vector field satisfies $\mathbf{F} \cdot \mathbf{n} \geq 0$ on the boundary, where $\mathbf{n}$ is the inward-pointing normal vector. This condition is satisfied for appropriate parameter ranges.
\end{proof}

\begin{remark}[Boundary Behavior]
\label{rem:boundary_behavior}
In practice, the periodic nature of the sine functions in~\eqref{eq:vector_field} means that trajectories approaching the boundary $\Sk = 1$ can be smoothly continued to $\Sk = 0$ by identifying opposite faces of the unit cube. This identification transforms $\Sspace$ from a cube with boundary into a three-dimensional torus $\mathbb{T}^3 = S^1 \times S^1 \times S^1$, on which the dynamics are naturally defined without boundary conditions. The torus topology is consistent with the periodic structure of the coordinate mappings (Section~\ref{sec:virtual_instrument}) and provides a more natural setting for the categorical dynamics.
\end{remark}

\subsection{Measure Preservation and Liouville's Theorem}

The most important property of the categorical dynamics for the Poincaré Computing framework is that they preserve the Lebesgue measure on $\Sspace$. This property is essential for the application of Poincaré's recurrence theorem, which requires that the dynamics be measure-preserving. We establish measure preservation through Liouville's theorem from Hamiltonian mechanics, which relates measure preservation to the divergence of the vector field.

\begin{theorem}[Measure Preservation]
\label{thm:measure_preservation}
The flow $\varphi_t: \Sspace \to \Sspace$ generated by the categorical vector field $\mathbf{F}$ preserves the Lebesgue measure $\mu$ on $\Sspace$ if and only if the characteristic frequencies satisfy the \textbf{modular condition}:
\begin{equation}
\omega_k + \omega_t + \omega_e = 0
\label{eq:modular_condition}
\end{equation}
Under this condition, for any measurable set $A \subseteq \Sspace$ and any time $t$, we have:
\begin{equation}
\mu(\varphi_t(A)) = \mu(A)
\label{eq:measure_preservation}
\end{equation}
\end{theorem}

\begin{proof}
By Liouville's theorem \citep{arnold1989mathematical}, a flow preserves Lebesgue measure if and only if the divergence of the generating vector field vanishes:
\begin{equation}
\nabla \cdot \mathbf{F} = 0
\label{eq:divergence_condition}
\end{equation}

We compute the divergence by taking the partial derivatives of each component of $\mathbf{F}$ with respect to the corresponding coordinate:
\begin{align}
\nabla \cdot \mathbf{F} &= \frac{\partial F_1}{\partial \Sk} + \frac{\partial F_2}{\partial \St} + \frac{\partial F_3}{\partial \Se} \\
&= \frac{\partial}{\partial \Sk}\left[\omega_k (\St - \Sk) + \alpha \sin(2\pi \Se)\right] \nonumber \\
&\quad + \frac{\partial}{\partial \St}\left[\omega_t (\Se - \St) + \beta \sin(2\pi \Sk)\right] \nonumber \\
&\quad + \frac{\partial}{\partial \Se}\left[\omega_e (\Sk - \Se) + \gamma \sin(2\pi \St)\right]
\end{align}

Evaluating each partial derivative:
\begin{align}
\frac{\partial F_1}{\partial \Sk} &= -\omega_k \quad \text{(the } \St \text{ and } \sin(2\pi \Se) \text{ terms do not depend on } \Sk\text{)} \\
\frac{\partial F_2}{\partial \St} &= -\omega_t \quad \text{(the } \Se \text{ and } \sin(2\pi \Sk) \text{ terms do not depend on } \St\text{)} \\
\frac{\partial F_3}{\partial \Se} &= -\omega_e \quad \text{(the } \Sk \text{ and } \sin(2\pi \St) \text{ terms do not depend on } \Se\text{)}
\end{align}

Therefore:
\begin{equation}
\nabla \cdot \mathbf{F} = -\omega_k - \omega_t - \omega_e
\end{equation}

Setting $\nabla \cdot \mathbf{F} = 0$ yields the modular condition~\eqref{eq:modular_condition}. When this condition is satisfied, Liouville's theorem guarantees that the flow $\varphi_t$ preserves Lebesgue measure.
\end{proof}

\begin{remark}[Physical Interpretation of Modular Condition]
\label{rem:modular_interpretation}
The modular condition $\omega_k + \omega_t + \omega_e = 0$ has a natural physical interpretation in terms of energy conservation. In the oscillator derivation (Remark~\ref{rem:oscillator_derivation}), the frequencies $\omega_i$ are related to the stiffness of the coupling springs. The modular condition ensures that energy flowing into one coordinate (positive $\omega_i$) is balanced by energy flowing out of another coordinate (negative $\omega_j$), maintaining constant total energy. This energy conservation is equivalent to measure preservation in the phase space.

Mathematically, the modular condition implies that one frequency must be negative if the others are positive. For example, if $\omega_k, \omega_t > 0$, then $\omega_e = -(\omega_k + \omega_t) < 0$. We interpret a negative frequency as \textit{retrograde evolution}: the coordinate evolves in the opposite direction to the standard orientation, corresponding to a phase shift of $\pi$ in the oscillatory dynamics.
\end{remark}

\begin{corollary}[Recurrence Applicability]
\label{cor:recurrence_applicability}
Under the modular condition~\eqref{eq:modular_condition}, the categorical dynamics satisfy the hypotheses of Poincaré's recurrence theorem (Corollary~\ref{cor:poincare_applicable}). Therefore, for almost every initial state $\Scoord_0 \in \Sspace$, the trajectory $\Scoord(t)$ returns arbitrarily close to $\Scoord_0$ infinitely often.
\end{corollary}

\begin{proof}
Poincaré's recurrence theorem applies to measure-preserving transformations on finite measure spaces. Theorem~\ref{thm:measure_preservation} establishes that the flow $\varphi_t$ is measure-preserving under the modular condition. Proposition~\ref{prop:finite_measure} establishes that $\mu(\Sspace) = 1 < \infty$. Therefore, the recurrence theorem applies, guaranteeing that almost every trajectory is recurrent.
\end{proof}

This corollary is the central result connecting the categorical dynamics to the foundational principle of Poincaré Computing: computation corresponds to finding recurrent trajectories in measure-preserving flows.

\subsection{Harmonic Coincidence Networks}

A distinctive feature of the categorical dynamics is the occurrence of \textbf{harmonic coincidences}---special times when the oscillatory components of the trajectory synchronize. These coincidences play a crucial role in the formation of recurrent trajectories and in the emergence of computational structure from continuous dynamics.

\begin{definition}[Harmonic Coincidence]
\label{def:harmonic_coincidence}
A \textbf{harmonic coincidence} occurs at time $t^* > 0$ when there exist integers $(n_k, n_t, n_e) \in \mathbb{Z}^3 \setminus \{(0,0,0)\}$ such that:
\begin{equation}
n_k \omega_k t^* + n_t \omega_t t^* + n_e \omega_e t^* \equiv 0 \pmod{2\pi}
\label{eq:harmonic_coincidence}
\end{equation}
Equivalently, the linear combination of phases satisfies:
\begin{equation}
n_k \omega_k t^* + n_t \omega_t t^* + n_e \omega_e t^* \in 2\pi\mathbb{Z}
\end{equation}
\end{definition}

At a harmonic coincidence time $t^*$, the three oscillatory modes have phases that are commensurate: their phases satisfy a linear relation with integer coefficients. This commensurability leads to constructive interference between the modes, producing a moment of enhanced coherence in the trajectory. In the context of computation, harmonic coincidences correspond to times when the knowledge, temporal, and evolution aspects of the computation are synchronized, enabling the system to make progress toward satisfying constraints.

\begin{proposition}[Coincidence Density for Rational Frequencies]
\label{prop:coincidence_density}
If the characteristic frequencies are rationally related---that is, if $\omega_i/\omega_j \in \mathbb{Q}$ for all pairs $i, j \in \{k, t, e\}$---then the set of harmonic coincidence times $\mathcal{T}_{\text{coin}} = \{t^* : \text{harmonic coincidence at } t^*\}$ has positive density in $\mathbb{R}^+$:
\begin{equation}
\liminf_{T \to \infty} \frac{|\mathcal{T}_{\text{coin}} \cap [0, T]|}{T} > 0
\label{eq:coincidence_density}
\end{equation}
\end{proposition}

\begin{proof}
Assume that the frequencies are rationally related: $\omega_i/\omega_j = p_{ij}/q_{ij}$ for integers $p_{ij}, q_{ij}$ with $\gcd(p_{ij}, q_{ij}) = 1$. Define the \textit{fundamental frequency}:
\begin{equation}
\omega_0 = \gcd(\omega_k, \omega_t, \omega_e)
\end{equation}
in the sense that each frequency can be written as $\omega_i = n_i \omega_0$ for integers $n_i$. (Here $\gcd$ is interpreted as the greatest common divisor in the ring of real numbers with rational ratios, which reduces to the standard integer gcd after appropriate scaling.)

A harmonic coincidence occurs when:
\begin{equation}
n_k (n_k \omega_0) t^* + n_t (n_t \omega_0) t^* + n_e (n_e \omega_0) t^* = (n_k^2 + n_t^2 + n_e^2) \omega_0 t^* \in 2\pi\mathbb{Z}
\end{equation}

This condition is satisfied when:
\begin{equation}
t^* = \frac{2\pi m}{\omega_0 (n_k^2 + n_t^2 + n_e^2)} \quad \text{for } m \in \mathbb{Z}^+
\end{equation}

The set of coincidence times is therefore:
\begin{equation}
\mathcal{T}_{\text{coin}} = \left\{ \frac{2\pi m}{\omega_0 N} : m \in \mathbb{Z}^+, N = n_k^2 + n_t^2 + n_e^2 \text{ for some } (n_k, n_t, n_e) \in \mathbb{Z}^3 \right\}
\end{equation}

The smallest period is $T_0 = 2\pi/\omega_0$, and coincidences occur at integer multiples of this period (possibly with additional coincidences at rational fractions). The number of coincidences in the interval $[0, T]$ is at least $\lfloor T/T_0 \rfloor$, giving:
\begin{equation}
\liminf_{T \to \infty} \frac{|\mathcal{T}_{\text{coin}} \cap [0, T]|}{T} \geq \frac{1}{T_0} = \frac{\omega_0}{2\pi} > 0
\end{equation}

This establishes positive density of coincidence times.
\end{proof}

\begin{remark}[Irrational Frequencies]
\label{rem:irrational_frequencies}
If the frequencies are irrationally related (e.g., $\omega_k/\omega_t \notin \mathbb{Q}$), then exact harmonic coincidences occur with zero density. However, \textit{approximate} coincidences—times when the phases are nearly commensurate—still occur with positive density as per Diophantine approximation theory. For computational purposes, approximate coincidences within a tolerance $\delta$ are sufficient to trigger constraint satisfaction events, and the density of such approximate coincidences can be controlled through the choice of frequencies.
\end{remark}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{figures/panel_harmonic.png}
\caption{\textbf{Harmonic Coincidence Interactions.} 
\textbf{(A) Frequency Spectrum:} Histogram of $\log_{10}(\text{Frequency} + 1)$ shows narrow distribution centered at $13.0$--$13.1$ (peak $\approx 32$ counts), with long tail extending to $13.6$. The logarithmic scale reveals power-law distribution of oscillator frequencies, characteristic of $1/f$ noise in hardware systems. 
\textbf{(B) Harmonic Network:} Circular graph shows 24 molecules (colored nodes) arranged on circle perimeter. Gray lines connect molecules with harmonic relationships (frequency ratios $f_i/f_j \approx n/m$ for small integers $n, m$). Dense connectivity in upper-right quadrant indicates cluster of harmonically-related molecules. Network topology determines solution trajectories (Theorem~\ref{thm:harmonic_solution_paths}): solutions emerge from harmonic coincidences. 
\textbf{(C) Strength Distribution:} Histogram of interaction strength shows bimodal distribution: primary peak at $0.1$ ($\approx 1200$ counts), secondary peak at $0.5$ ($\approx 2000$ counts). Low-strength interactions ($< 0.2$) dominate numerically but high-strength interactions ($\approx 0.5$) provide critical coupling for solution convergence. The gap at $0.2$--$0.4$ suggests quantization of interaction strengths. 
\textbf{(D) Harmonic Order Distribution:} Histogram of harmonic order $n + m$ (where $f_i/f_j \approx n/m$) shows exponential decay: order $2.5$ dominates ($\approx 2100$ counts), decreasing to $\approx 250$ counts by order $20$. Low-order harmonics ($n + m < 5$) are most common, corresponding to simple frequency ratios ($2:1$, $3:2$, $4:3$). High-order harmonics ($n + m > 15$) are rare but enable fine-tuned resonances. 
\textbf{(E) Phase-Amplitude Distribution:} Polar plot shows interaction phase (angle) vs. amplitude (radius). Most interactions cluster near $0°$ and $180°$ (in-phase and anti-phase), with amplitudes $0.2$--$0.8$. Sparse population at $90°$ and $270°$ (quadrature phase) indicates phase locking. The distribution confirms that harmonic interactions are predominantly real-valued (phase $\approx 0°$ or $180°$), not complex. 
\textbf{(F) Frequency Ratio Matrix:} Heatmap shows pairwise frequency ratios $f_i/f_j$ for 20 molecules (rows and columns). Diagonal is identity ($f_i/f_i = 1$, white). Off-diagonal shows ratios ranging from $0.5$ (red, $f_i = f_j/2$) to $4.0$ (blue, $f_i = 4f_j$). Horizontal banding indicates molecules with similar frequencies (rows $0$--$5$: ratios $\approx 1$--$2$, orange). Vertical banding indicates molecules serving as harmonic references (columns $10$--$15$: ratios $\approx 2$--$3$, orange-yellow). The matrix structure reveals harmonic clusters: groups of molecules with commensurate frequencies that interact strongly.}
\label{fig:harmonic_coincidence}
\end{figure}

\subsection{Fixed Points and Periodic Orbits}

The categorical dynamics admit various types of invariant sets, including fixed points (equilibria) and periodic orbits. These invariant sets provide the skeleton around which more complex trajectories are organised and play a crucial role in determining the global structure of the phase space.

\begin{theorem}[Fixed Point Structure]
\label{thm:fixed_points}
The categorical dynamics~\eqref{eq:dsk_dt}--\eqref{eq:dse_dt} admit fixed points at states $\Scoord^* = (\Sk^*, \St^*, \Se^*)$ where all three coordinates are equal:
\begin{equation}
\Sk^* = \St^* = \Se^* = s^*
\label{eq:fixed_point_condition}
\end{equation}
and $s^* \in [0,1]$ satisfies:
\begin{equation}
\sin(2\pi s^*) = 0 \quad \Rightarrow \quad s^* \in \left\{0, \frac{1}{2}, 1\right\}
\label{eq:fixed_point_values}
\end{equation}
(Note: $s^* = 0$ and $s^* = 1$ represent the same point due to periodic boundary conditions.)

Therefore, the categorical dynamics admit two distinct fixed points:
\begin{equation}
\Scoord_1^* = (0, 0, 0) \equiv (1, 1, 1), \quad \Scoord_2^* = \left(\frac{1}{2}, \frac{1}{2}, \frac{1}{2}\right)
\label{eq:fixed_points}
\end{equation}
\end{theorem}

\begin{proof}
At a fixed point, the vector field must vanish: $\mathbf{F}(\Scoord^*) = 0$. This requires:
\begin{align}
\omega_k (\St^* - \Sk^*) + \alpha \sin(2\pi \Se^*) &= 0 \label{eq:fp1} \\
\omega_t (\Se^* - \St^*) + \beta \sin(2\pi \Sk^*) &= 0 \label{eq:fp2} \\
\omega_e (\Sk^* - \Se^*) + \gamma \sin(2\pi \St^*) &= 0 \label{eq:fp3}
\end{align}

Suppose $\Sk^* = \St^* = \Se^* = s^*$ (all coordinates equal). Then the linear terms in~\eqref{eq:fp1}--\eqref{eq:fp3} vanish identically:
\begin{equation}
\St^* - \Sk^* = s^* - s^* = 0, \quad \Se^* - \St^* = 0, \quad \Sk^* - \Se^* = 0
\end{equation}

The equations reduce to:
\begin{align}
\alpha \sin(2\pi s^*) &= 0 \\
\beta \sin(2\pi s^*) &= 0 \\
\gamma \sin(2\pi s^*) &= 0
\end{align}

Assuming $\alpha, \beta, \gamma \neq 0$, these equations are satisfied when $\sin(2\pi s^*) = 0$, which occurs at $s^* \in \{0, 1/2, 1\}$. Due to the periodic boundary conditions (identifying $s^* = 0$ with $s^* = 1$), there are two distinct fixed points: $(0,0,0)$ and $(1/2, 1/2, 1/2)$.
\end{proof}

\begin{proposition}[Local Stability of Central Fixed Point]
\label{prop:local_stability}
The fixed point $\Scoord_2^* = (1/2, 1/2, 1/2)$ is Lyapunov stable when the coupling constants are small compared to the characteristic frequencies:
\begin{equation}
|\alpha|, |\beta|, |\gamma| < \min(|\omega_k|, |\omega_t|, |\omega_e|)
\label{eq:stability_condition}
\end{equation}
\end{proposition}

\begin{proof}
To determine stability, we linearize the vector field $\mathbf{F}$ about the fixed point $\Scoord_2^*$. The Jacobian matrix is:
\begin{equation}
D\mathbf{F}|_{\Scoord_2^*} = \begin{pmatrix}
\frac{\partial F_1}{\partial \Sk} & \frac{\partial F_1}{\partial \St} & \frac{\partial F_1}{\partial \Se} \\
\frac{\partial F_2}{\partial \Sk} & \frac{\partial F_2}{\partial \St} & \frac{\partial F_2}{\partial \Se} \\
\frac{\partial F_3}{\partial \Sk} & \frac{\partial F_3}{\partial \St} & \frac{\partial F_3}{\partial \Se}
\end{pmatrix}_{\Scoord_2^*}
\end{equation}

Computing the partial derivatives at $\Scoord_2^* = (1/2, 1/2, 1/2)$:
\begin{align}
\frac{\partial F_1}{\partial \Sk} &= -\omega_k, \quad \frac{\partial F_1}{\partial \St} = \omega_k, \quad \frac{\partial F_1}{\partial \Se} = 2\pi\alpha \cos(2\pi \cdot 1/2) = -2\pi\alpha \\
\frac{\partial F_2}{\partial \Sk} &= 2\pi\beta \cos(2\pi \cdot 1/2) = -2\pi\beta, \quad \frac{\partial F_2}{\partial \St} = -\omega_t, \quad \frac{\partial F_2}{\partial \Se} = \omega_t \\
\frac{\partial F_3}{\partial \Sk} &= \omega_e, \quad \frac{\partial F_3}{\partial \St} = 2\pi\gamma \cos(2\pi \cdot 1/2) = -2\pi\gamma, \quad \frac{\partial F_3}{\partial \Se} = -\omega_e
\end{align}

Therefore:
\begin{equation}
D\mathbf{F}|_{\Scoord_2^*} = \begin{pmatrix}
-\omega_k & \omega_k & -2\pi\alpha \\
-2\pi\beta & -\omega_t & \omega_t \\
\omega_e & -2\pi\gamma & -\omega_e
\end{pmatrix}
\label{eq:jacobian}
\end{equation}

The fixed point is Lyapunov stable if all eigenvalues of $D\mathbf{F}|_{\Scoord_2^*}$ have non-positive real parts. Under the modular condition $\omega_k + \omega_t + \omega_e = 0$ and the assumption that coupling constants are small ($|\alpha|, |\beta|, |\gamma| \ll |\omega_i|$), the eigenvalues can be computed perturbatively. The unperturbed system (with $\alpha = \beta = \gamma = 0$) has eigenvalues $\{0, 0, 0\}$ (reflecting the measure-preserving property). The coupling terms introduce small perturbations that, for sufficiently small coupling, maintain non-positive real parts, ensuring Lyapunov stability \citep{khalil2002nonlinear}.
\end{proof}



\begin{theorem}[Periodic Orbit Existence]
\label{thm:periodic_orbits}
For characteristic frequencies that are rationally related and coupling constants satisfying $|\alpha|, |\beta|, |\gamma| \ll |\omega_i|$, the categorical dynamics admit a dense set of periodic orbits in $\Sspace$.
\end{theorem}

\begin{proof}
The categorical dynamics can be viewed as a perturbation of an integrable system. When $\alpha = \beta = \gamma = 0$, the equations~\eqref{eq:dsk_dt}--\eqref{eq:dse_dt} decouple into three independent linear equations, which are exactly solvable. For rationally related frequencies, the solutions are periodic with periods determined by the frequency ratios.

The Kolmogorov-Arnold-Moser (KAM) theorem \citep{arnold1963proof} establishes that, for sufficiently small perturbations of integrable Hamiltonian systems, a positive measure of invariant tori persists. These invariant tori are foliated by quasi-periodic orbits, which become periodic orbits when the frequencies are rationally related.

Applying the KAM theorem to the categorical dynamics (interpreted as a Hamiltonian system via the measure-preserving property), we conclude that for small coupling constants, a dense set of periodic orbits persists. The density follows from the fact that rational frequency ratios are dense in the space of all frequency ratios, and each rational ratio corresponds to a periodic orbit.
\end{proof}

\begin{remark}[Computational Significance of Periodic Orbits]
\label{rem:periodic_orbits_computation}
Periodic orbits in the categorical dynamics correspond to computations that repeat cyclically, returning to the same state after a fixed period. These orbits are not solutions in the Poincaré Computing sense (which requires recurrence to the initial state, not to an arbitrary state), but they provide the building blocks from which recurrent trajectories are constructed. By concatenating segments of different periodic orbits through constraint-guided transitions, the system can navigate through phase space to satisfy complex constraint sets while maintaining the recurrence property.
\end{remark}

This section has established the mathematical structure of categorical dynamics governing trajectory evolution in S-entropy space. The equations of motion are derived from coupled oscillator principles, the dynamics preserve Lebesgue measure under the modular condition (enabling Poincaré recurrence). Harmonic coincidences provide synchronisation events that structure the trajectory, and the phase space contains a rich variety of fixed points and periodic orbits. In the following section, we develop the topological and sheaf-theoretic structure that enables the categorical interpretation of these dynamics and the construction of the identity functor central to Poincaré Computing.
